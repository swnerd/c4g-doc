{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview Conductor for Gluent makes managing offloads with Gluent Data Platform easier. The orchestration of tasks such as offload execution, monitoring and partition dropping can be done through a single UI. Conductor provides global-, database- and job-level parameters for job execution, notifications, and partition removal. This drives consistency in the operation of Gluent software across the environment. Setting Up Conductor for Gluent integrates Gluent Advisor findings with existing database information to make offloading candidate tables simple and stress-free. Once defined, jobs can be scheduled to execute offload commands and drop offloaded partitions if desired. Managing Conductor for Gluent\u2019s job status dashboard makes it simple to view failed, completed and executing jobs. Failed jobs can be re-run as required. Conductor provides a simple way to create and manage jobs via a wizard. Managing existing jobs (removing, changing, deactivating, etc.) is driven solely through the UI. Statistics One of the primary use cases for Gluent Data Platform is offloading data to a cheaper, more modern data platform. Conductor for Gluent captures how much space is offloaded and presents it in a simple, visual display. Centralized reporting on space savings makes tracking this KPI easy.","title":"Home"},{"location":"#overview","text":"Conductor for Gluent makes managing offloads with Gluent Data Platform easier. The orchestration of tasks such as offload execution, monitoring and partition dropping can be done through a single UI. Conductor provides global-, database- and job-level parameters for job execution, notifications, and partition removal. This drives consistency in the operation of Gluent software across the environment.","title":"Overview"},{"location":"#setting-up","text":"Conductor for Gluent integrates Gluent Advisor findings with existing database information to make offloading candidate tables simple and stress-free. Once defined, jobs can be scheduled to execute offload commands and drop offloaded partitions if desired.","title":"Setting Up"},{"location":"#managing","text":"Conductor for Gluent\u2019s job status dashboard makes it simple to view failed, completed and executing jobs. Failed jobs can be re-run as required. Conductor provides a simple way to create and manage jobs via a wizard. Managing existing jobs (removing, changing, deactivating, etc.) is driven solely through the UI.","title":"Managing"},{"location":"#statistics","text":"One of the primary use cases for Gluent Data Platform is offloading data to a cheaper, more modern data platform. Conductor for Gluent captures how much space is offloaded and presents it in a simple, visual display. Centralized reporting on space savings makes tracking this KPI easy.","title":"Statistics"},{"location":"2.2.x/install-2.2.x/","text":"Front End Installation The frontend installation should be done anytime the central Conductor for Gluent repository will be used along with the Conductor for Gluent Apex application. If using the Conductor for Gluent in the standalone mode, please skip down to the backend installation section. Prerequisites Oracle 12+ Database (created with DBCA or Manually) Note 1: : Apex requires that Oracle Text and JVM options be installed. No other options are required. Note 2: : Apex and Conductor for Gluent should be installed into the container database, so be sure to run the alter session command to set the container, e.g. ALTER SESSION SET CONTAINER = XEPDB1. Apex 19.2 Setup Create Tablespace for Apex (if one does not exist) SQL> -- Create Tablespace for Apex - Example create tablespace tbs_apex datafile '/u01/app/oracle/oradata/testinst/tbs_apex01.dbf' size 100m autoextend on maxsize 1000m; Copy Apex 19.2 to database host Example Copy to Oracle User Home scp apex_19.2_en.zip {oracle user}@{db host}:. Remove Existing Apex Software Remove Apex from database (if necessary) cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- Disable existing EXEC DBMS_XDB.SETHTTPPORT(0); SQL> SQL> -- Remove Apex @apxremov.sql PL/SQL procedure successfully completed. ... ... ... ... ...Application Express Removed ******************************************************************** ** You must exit this SQL*Plus session before running apexins.sql ** ******************************************************************** SQL> exit Move original apex software out of the way cd $ORACLE_HOME mv apex apex.orig Install Apex Unzip Apex 19.2 software example statement if uploaded to user's home directory: cd $ORACLE_HOME unzip ~/apex_19.2_en.zip Install Apex 19.2 in database cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- Runtime install with 4 parms (apex tbs, apex tbs, temp tbs, image loc) @apxrtins.sql tbs_apex tbs_apex temp /i/ ...set_appun.sql PL/SQL procedure successfully completed. ... ... ... ... PL/SQL procedure successfully completed. Thank you for installing Oracle Application Express 19.2.0.00.18 Oracle Application Express is installed in the APEX_190200 schema. The structure of the link to the Application Express administration services is as follows: http://host:port/pls/apex/apex_admin (Oracle HTTP Server with mod_plsql) http://host:port/apex/apex_admin (Oracle XML DB HTTP listener with the embedded PL/SQL gateway) http://host:port/apex/apex_admin (Oracle REST Data Services) The structure of the link to the Application Express development interface is as follows: http://host:port/pls/apex (Oracle HTTP Server with mod_plsql) http://host:port/apex (Oracle XML DB HTTP listener with the embedded PL/SQL gateway) http://host:port/apex (Oracle REST Data Services) timing for: Phase 3 (Switch) Elapsed: 00:00:08.39 timing for: Complete Installation Elapsed: 00:06:24.88 PL/SQL procedure successfully completed. Change / Setup Apex Administrator cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- no parameters @apxchpwd.sql ...set_appun.sql ================================================================================ This script can be used to change the password of an Application Express instance administrator. If the user does not yet exist, a user record will be created. ================================================================================ Enter the administrator's username [ADMIN] User \"ADMIN\" does not yet exist and will be created. Enter ADMIN's email [ADMIN] {specify email address} Enter ADMIN's password [] Created instance administrator ADMIN. Enable Embedded PL/SQL Gateway and other configuration items Enable Embedded PL/SQL Gateway and other configuration items cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- one parameter is oracle_home @apex_epg_config.sql /u01/app/oracle/product/12.2.0/dbhome_1 PL/SQL procedure successfully completed. ... ... ... ... PL/SQL procedure successfully completed. Commit complete. alter user anonymous identified by \"{complex password}\" account unlock; alter user xdb identified by \"{complex password}\" account unlock; alter user apex_public_user identified by \"{complex password}\" account unlock; EXEC DBMS_XDB.SETHTTPPORT(8080); BEGIN DBMS_NETWORK_ACL_ADMIN.APPEND_HOST_ACE( host => '*', ace => xs$ace_type(privilege_list => xs$name_list('connect'), principal_name => 'APEX_190200', principal_type => xs_acl.ptype_db)); END; / -- Below script contents can be found in Appendix A of this document @xdbconfig_anonymous.sql Schema Install Create Tablespace Create tablespace to contain the conductor_for_gluent's repository, for example: create tablespace tbs_c4g datafile '+dg_data' size 100M autoextend on next 1M maxsize 100M; or create tablespace tbs_c4g datafile '/u01/app/oracle/oradata/testinst/tbs_c4g01.dbf' size 100M autoextend on next 1M maxsize 1000M; Create User and Privileges Create user conductor_for_gluent with above tablespace as the default tablespace, for example: create user conductor_for_gluent identified by \"{complex password}\" default tablespace tbs_c4g; alter user conductor_for_gluent quota unlimited on tbs_c4g; grant connect to conductor_for_gluent; grant resource to conductor_for_gluent; grant create database link to conductor_for_gluent; grant create synonym to conductor_for_gluent; grant create view to conductor_for_gluent; grant select any dictionary to conductor_for_gluent; grant select any table to conductor_for_gluent; Install and Setup the Objects The installation SQL scripts are located in gui directory where the backend scripts were installed (usually /u01/app/gluent/scripts or /u01/app/gluent/c4g-scripts . From this directory connect to the apex database (usually c4g_central is the tns name to use: You can set your environment to use the tnsnames.ora file you created during the backend setup. For example: cd /u01/app/gluent/c4g-scripts/tns export TNS_ADMIN=`pwd` cd ../gui sqlplus system/{complex password}@c4g_central Schema Setup Run the sql, no parameters - 1 prompt for tablespace spool c4g-setup-schema.log @c4g-setup-schema.sql Tablespace: tbs_c4g spool off Source Setup Run the sql, no parameters spool c4g-setup-source.log @c4g-setup-source.sql spool off Seed Data Setup Run the sql, no parameters spool c4g-setup-seeddata.log @c4g-setup-seeddata.sql commit; spool off Note : Be sure to commit after running the script. Help Text Setup Run the sql, no parameters spool c4g-setup-helptext.log @c4g-setup-helptext.sql commit; spool off Note : Be sure to commit after running the script. Apex Application Install Create the Workspace SQL> -- run the sql, no parameters @c4g-apex-workspace.sql \"Import\" the runtime app (sql script) SQL> -- run the sql, no parameters @c4g-apex-application.sql Connecting to Conductor for Gluent http://{hostname}:8080/apex/f?p=100:LOGIN_DESKTOP:25119307751525::::: Default Users Admin User: c4g_admin App User: c4g_user Please contact your Conductor for Gluent provider for password. \u2003 Backend Software Installations Conductor for Gluent Backend Software Usage Options The Conductor for Gluent Backend (evolved from AEG Gluent Toolkit) has three possible modes of operation: Standalone mode Local repository mode Full Conductor for Gluent Front-end and Back-end with Central Repository The standalone and local repository modes of operation have been around and used in production environments for several years (initial deployment to a production environment in Q1 2017). Enhancements have been done over the subsequent time period, including the local repository mode. The central repository integration with Conductor for Gluent frontend was done in 2019. Standalone No additional software is needed or required. The software just provides a consistent job-oriented method for running gluent offloads. Jobs are setup through flat \"job\" files. Scheduling of the individual jobs requires a cron entry per job. Standalone with local repository Same as standalone. Additionally, some result information is stored in tables under the gluent_adm schema, such as, tables offloaded, job success, when possible some information on bytes transferred. Full Conductor for Gluent with Central Repository Jobs are configured and scheduled through the front-end software. A single cron job is required to handle the launching of jobs based on schedule in the central repository. All information gathered about the job success, partitions offloaded, etc is stored in the central repository. Prerequisites Gluent Software Installed Cloudera with Impala only parquet-tools available in the path of the edge node for the ssh user when using Full Conductor for Gluent Front-end and Back-end with Central Repository - usually found in /var/lib/alternatives. Central Repository Database Installed (see C4G Frontend Setup Guide) Unpack Software A tar file will be supplied. The tar file should be unpacked in a directory such as, c4g-scripts or scripts or similar. For example: cd /u01/app/gluent mkdir c4g-scripts cd c4g-scripts tar xf {tar file name} Environment File Setup Note on split configuration : If gluent is setup in a split configuration, then certain scripts will not function, and certain variables are not set in the environment files. conductor_for_gluent.env A template for the conductor_for_gluent.env file can be found under the env/templates directory - it is recommended that you copy the template file as a starting point. PATH - This export of the path is to make sure the oraenv script is in the path. ORACLE_SID - Set this to the Oracle SID of the database which is being offloaded. ORAENV_ASK - Set for no prompts. oraenv - script to set the oracle environment. Unset ORAENV_ASK As this shell script runs SQL, the SQL_PATH variable is unset, so as not to get possible interference (same name scripts, login.sql files, etc). OFFLOAD_HOME=\"/u01/app/gluent/offload\" - Update OFFLOAD_HOME to the location of the gluent software offload home. . $OFFLOAD_HOME/conf/offload.env - DO NOT CHANGE C4G_REPO NONE - No Repository; standalone mode without a repository RUNTIME- run a local repository that stores information generated a runtime FULL - run a central repository that stores information about jobs, schedules, etc. HADOOP_HOST - defaults to the HDFS_CMD_HOST HADOOP_SSH_USER - set to the target user on hadoop for ssh G_ERROR_WORDS - Words and phrases used when determining if a possible error occurred. TNS_ADMIN - Always set to ${tnsdir} - DO NOT CHANGE AEG_GLUENT_REPO_SERVICE - service name to be used when connecting to the central repository AEG_GLUENT_LOCAL_SERVICE - service name to be used when connecting to the local database dstr - service name used in local repository and standalone mode impala_node - automatically determined but can be overridden IMPALA_SHELL_CMD - command with options need to run impala-shell run-gluent-job.env A template for the file can be found under the env/templates directory - it is recommended that you copy the template file as a starting point. PRECREATED_DBS - true or false (defaults to false) Only add/update if gluent is not allowed to create databases on impala G_BEGIN_NOTIFY - true or false G_BEGIN_MAIL_LIST - email addresses space separated in quotes. G_SUCCESS_NOTIFY - true or false G_SUCCESS_MAIL_LIST - email addresses space separated in quotes. G_ERROR_NOTIFY -true or false G_ERROR_MAIL_LIST - email addresses space separated in quotes. setup-wallet.env A template for the file can be found under the env/templates directory - it is recommended that you copy the template file as a starting point. AEG_WALLET_LOCATION=/u01/app/gluent/scripts/tns - update to the location to contain the wallet WALLET_ENTRY - the wallet entry you want to setup (corresponds to a TNS service name) Configuration File Setup If not running in the Central Repository mode, then 2 configuration files can be created to set default offload and present parameters. offload-defaults.cfg present-defaults.cfg User Setup in Local Database for Central Repository Mode A user is needed in the local database with the following username: CONDUCTOR_FOR_GLUENT create user conductor_for_gluent identified by \"{complex password}\" default tablespace users temporary tablespace temp; The privileges needed are: GRANT CONNECT TO CONDUCTOR_FOR_GLUENT; GRANT GLUENT_OFFLOAD_ROLE TO CONDUCTOR_FOR_GLUENT; GRANT SELECT ANY DICTIONARY TO CONDUCTOR_FOR_GLUENT; GRANT SELECT ANY TABLE TO CONDUCTOR_FOR_GLUENT; -- Needed for Conductor for Gluent to do partition maintenance GRANT DROP ANY TABLE TO CONDUCTOR_FOR_GLUENT; GRANT ALTER ANY TABLE TO CONDUCTOR_FOR_GLUENT; An alternative to the ANY TABLE privilege is to preform the grant(s) on the tables to be offloaded. TNS Setup This is needed for all 3 modes of the backend software. TNSNAMES.ORA A TNSNAMES.ORA file needs to be created in the tns subdirectory. For the no repository option or the local repository option, one entry for the local DB being offloaded is needed. For the central repository mode, two entries are needed: one for local DB and a second for the central repository. Suggested names are as follows: c4g_local c4g_central Historically, the tns entry was: gluent_conn A sample file is located under the tns/sample directory, showing a simple tns entry. Wallet Setup For Full Conductor for Gluent, run the following: ./setup-wallet new c4g_local ./setup-wallet add c4g_central For Standalone or Runtime Repository modes, run the following: ./setup-wallet new gluent_conn Crontab Setup Once the backend and frontend software are installed, add a cron entry to run the launch script. The job should be like the following with the appropriate path specified: * * * * * /u01/app/gluent/scripts/bin/launch-gluent-jobs {DB/Container Name} > /u01/app/gluent/scripts/log/launch-gluent-jobs-cron.log 2>&1 Appendix A - xdbconfig_anonymous.sql DECLARE l_configxml XMLTYPE; l_value VARCHAR2(5) := 'true'; BEGIN l_configxml := DBMS_XDB.cfg_get(); IF l_configxml.existsNode('/xdbconfig/sysconfig/protocolconfig/httpconfig/allow-repository-anonymous-access') = 0 THEN -- Add config element begin SELECT insertChildXML( l_configxml , '/xdbconfig/sysconfig/protocolconfig/httpconfig' , 'allow-repository-anonymous-access' , XMLType('<allow-repository-anonymous-access xmlns=\"http://xmlns.oracle.com/xdb/xdbconfig.xsd\">' || l_value || '</allow-repository-anonymous-access>') , 'xmlns=\"http://xmlns.oracle.com/xdb/xdbconfig.xsd\"' ) INTO l_configxml FROM dual; exception when others then dbms_output.put_line( 'insert' ); -- ' raise; end; DBMS_OUTPUT.put_line('xdbconfig for anonymous now inserted.'); ELSE -- Update existing config element. begin SELECT updateXML( DBMS_XDB.cfg_get() , '/xdbconfig/sysconfig/protocolconfig/httpconfig/allow-repository-anonymous-access/text()' , XMLType('<allow-repository-anonymous-access xmlns=\"http://xmlns.oracle.com/xdb/xdbconfig.xsd\">' || l_value || '</allow-repository-anonymous-access>') , 'xmlns=\"http://xmlns.oracle.com/xdb/xdbconfig.xsd\"' ) INTO l_configxml FROM dual; exception when others then dbms_output.put_line( 'update'); -- ' raise; end; DBMS_OUTPUT.put_line('xdbconfig for anonymous now updated.'); END IF; DBMS_XDB.cfg_update(l_configxml); DBMS_XDB.cfg_refresh; END; /","title":"Installation"},{"location":"2.2.x/install-2.2.x/#front-end-installation","text":"The frontend installation should be done anytime the central Conductor for Gluent repository will be used along with the Conductor for Gluent Apex application. If using the Conductor for Gluent in the standalone mode, please skip down to the backend installation section.","title":"Front End Installation"},{"location":"2.2.x/install-2.2.x/#prerequisites","text":"Oracle 12+ Database (created with DBCA or Manually) Note 1: : Apex requires that Oracle Text and JVM options be installed. No other options are required. Note 2: : Apex and Conductor for Gluent should be installed into the container database, so be sure to run the alter session command to set the container, e.g. ALTER SESSION SET CONTAINER = XEPDB1.","title":"Prerequisites"},{"location":"2.2.x/install-2.2.x/#apex-192-setup","text":"Create Tablespace for Apex (if one does not exist) SQL> -- Create Tablespace for Apex - Example create tablespace tbs_apex datafile '/u01/app/oracle/oradata/testinst/tbs_apex01.dbf' size 100m autoextend on maxsize 1000m;","title":"Apex 19.2 Setup"},{"location":"2.2.x/install-2.2.x/#copy-apex-192-to-database-host","text":"Example Copy to Oracle User Home scp apex_19.2_en.zip {oracle user}@{db host}:.","title":"Copy Apex 19.2 to database host"},{"location":"2.2.x/install-2.2.x/#remove-existing-apex-software","text":"Remove Apex from database (if necessary) cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- Disable existing EXEC DBMS_XDB.SETHTTPPORT(0); SQL> SQL> -- Remove Apex @apxremov.sql PL/SQL procedure successfully completed. ... ... ... ... ...Application Express Removed ******************************************************************** ** You must exit this SQL*Plus session before running apexins.sql ** ******************************************************************** SQL> exit Move original apex software out of the way cd $ORACLE_HOME mv apex apex.orig","title":"Remove Existing Apex Software"},{"location":"2.2.x/install-2.2.x/#install-apex","text":"","title":"Install Apex"},{"location":"2.2.x/install-2.2.x/#unzip-apex-192-software","text":"example statement if uploaded to user's home directory: cd $ORACLE_HOME unzip ~/apex_19.2_en.zip","title":"Unzip Apex 19.2 software"},{"location":"2.2.x/install-2.2.x/#install-apex-192-in-database","text":"cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- Runtime install with 4 parms (apex tbs, apex tbs, temp tbs, image loc) @apxrtins.sql tbs_apex tbs_apex temp /i/ ...set_appun.sql PL/SQL procedure successfully completed. ... ... ... ... PL/SQL procedure successfully completed. Thank you for installing Oracle Application Express 19.2.0.00.18 Oracle Application Express is installed in the APEX_190200 schema. The structure of the link to the Application Express administration services is as follows: http://host:port/pls/apex/apex_admin (Oracle HTTP Server with mod_plsql) http://host:port/apex/apex_admin (Oracle XML DB HTTP listener with the embedded PL/SQL gateway) http://host:port/apex/apex_admin (Oracle REST Data Services) The structure of the link to the Application Express development interface is as follows: http://host:port/pls/apex (Oracle HTTP Server with mod_plsql) http://host:port/apex (Oracle XML DB HTTP listener with the embedded PL/SQL gateway) http://host:port/apex (Oracle REST Data Services) timing for: Phase 3 (Switch) Elapsed: 00:00:08.39 timing for: Complete Installation Elapsed: 00:06:24.88 PL/SQL procedure successfully completed.","title":"Install Apex 19.2 in database"},{"location":"2.2.x/install-2.2.x/#change-setup-apex-administrator","text":"cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- no parameters @apxchpwd.sql ...set_appun.sql ================================================================================ This script can be used to change the password of an Application Express instance administrator. If the user does not yet exist, a user record will be created. ================================================================================ Enter the administrator's username [ADMIN] User \"ADMIN\" does not yet exist and will be created. Enter ADMIN's email [ADMIN] {specify email address} Enter ADMIN's password [] Created instance administrator ADMIN.","title":"Change / Setup Apex Administrator"},{"location":"2.2.x/install-2.2.x/#enable-embedded-plsql-gateway-and-other-configuration-items","text":"","title":"Enable Embedded PL/SQL Gateway and other configuration items"},{"location":"2.2.x/install-2.2.x/#enable-embedded-plsql-gateway-and-other-configuration-items_1","text":"cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- one parameter is oracle_home @apex_epg_config.sql /u01/app/oracle/product/12.2.0/dbhome_1 PL/SQL procedure successfully completed. ... ... ... ... PL/SQL procedure successfully completed. Commit complete. alter user anonymous identified by \"{complex password}\" account unlock; alter user xdb identified by \"{complex password}\" account unlock; alter user apex_public_user identified by \"{complex password}\" account unlock; EXEC DBMS_XDB.SETHTTPPORT(8080); BEGIN DBMS_NETWORK_ACL_ADMIN.APPEND_HOST_ACE( host => '*', ace => xs$ace_type(privilege_list => xs$name_list('connect'), principal_name => 'APEX_190200', principal_type => xs_acl.ptype_db)); END; / -- Below script contents can be found in Appendix A of this document @xdbconfig_anonymous.sql","title":"Enable Embedded PL/SQL Gateway and other configuration items"},{"location":"2.2.x/install-2.2.x/#schema-install","text":"","title":"Schema Install"},{"location":"2.2.x/install-2.2.x/#create-tablespace","text":"Create tablespace to contain the conductor_for_gluent's repository, for example: create tablespace tbs_c4g datafile '+dg_data' size 100M autoextend on next 1M maxsize 100M; or create tablespace tbs_c4g datafile '/u01/app/oracle/oradata/testinst/tbs_c4g01.dbf' size 100M autoextend on next 1M maxsize 1000M;","title":"Create Tablespace"},{"location":"2.2.x/install-2.2.x/#create-user-and-privileges","text":"Create user conductor_for_gluent with above tablespace as the default tablespace, for example: create user conductor_for_gluent identified by \"{complex password}\" default tablespace tbs_c4g; alter user conductor_for_gluent quota unlimited on tbs_c4g; grant connect to conductor_for_gluent; grant resource to conductor_for_gluent; grant create database link to conductor_for_gluent; grant create synonym to conductor_for_gluent; grant create view to conductor_for_gluent; grant select any dictionary to conductor_for_gluent; grant select any table to conductor_for_gluent;","title":"Create User and Privileges"},{"location":"2.2.x/install-2.2.x/#install-and-setup-the-objects","text":"The installation SQL scripts are located in gui directory where the backend scripts were installed (usually /u01/app/gluent/scripts or /u01/app/gluent/c4g-scripts . From this directory connect to the apex database (usually c4g_central is the tns name to use: You can set your environment to use the tnsnames.ora file you created during the backend setup. For example: cd /u01/app/gluent/c4g-scripts/tns export TNS_ADMIN=`pwd` cd ../gui sqlplus system/{complex password}@c4g_central","title":"Install and Setup the Objects"},{"location":"2.2.x/install-2.2.x/#schema-setup","text":"Run the sql, no parameters - 1 prompt for tablespace spool c4g-setup-schema.log @c4g-setup-schema.sql Tablespace: tbs_c4g spool off","title":"Schema Setup"},{"location":"2.2.x/install-2.2.x/#source-setup","text":"Run the sql, no parameters spool c4g-setup-source.log @c4g-setup-source.sql spool off","title":"Source Setup"},{"location":"2.2.x/install-2.2.x/#seed-data-setup","text":"Run the sql, no parameters spool c4g-setup-seeddata.log @c4g-setup-seeddata.sql commit; spool off Note : Be sure to commit after running the script.","title":"Seed Data Setup"},{"location":"2.2.x/install-2.2.x/#help-text-setup","text":"Run the sql, no parameters spool c4g-setup-helptext.log @c4g-setup-helptext.sql commit; spool off Note : Be sure to commit after running the script.","title":"Help Text Setup"},{"location":"2.2.x/install-2.2.x/#apex-application-install","text":"","title":"Apex Application Install"},{"location":"2.2.x/install-2.2.x/#create-the-workspace","text":"SQL> -- run the sql, no parameters @c4g-apex-workspace.sql","title":"Create the Workspace"},{"location":"2.2.x/install-2.2.x/#import-the-runtime-app-sql-script","text":"SQL> -- run the sql, no parameters @c4g-apex-application.sql","title":"\"Import\" the runtime app (sql script)"},{"location":"2.2.x/install-2.2.x/#connecting-to-conductor-for-gluent","text":"http://{hostname}:8080/apex/f?p=100:LOGIN_DESKTOP:25119307751525::::: Default Users Admin User: c4g_admin App User: c4g_user Please contact your Conductor for Gluent provider for password.","title":"Connecting to Conductor for Gluent"},{"location":"2.2.x/install-2.2.x/#backend-software-installations","text":"","title":"Backend Software Installations"},{"location":"2.2.x/install-2.2.x/#conductor-for-gluent-backend-software-usage-options","text":"The Conductor for Gluent Backend (evolved from AEG Gluent Toolkit) has three possible modes of operation: Standalone mode Local repository mode Full Conductor for Gluent Front-end and Back-end with Central Repository The standalone and local repository modes of operation have been around and used in production environments for several years (initial deployment to a production environment in Q1 2017). Enhancements have been done over the subsequent time period, including the local repository mode. The central repository integration with Conductor for Gluent frontend was done in 2019.","title":"Conductor for Gluent Backend Software Usage Options"},{"location":"2.2.x/install-2.2.x/#standalone","text":"No additional software is needed or required. The software just provides a consistent job-oriented method for running gluent offloads. Jobs are setup through flat \"job\" files. Scheduling of the individual jobs requires a cron entry per job.","title":"Standalone"},{"location":"2.2.x/install-2.2.x/#standalone-with-local-repository","text":"Same as standalone. Additionally, some result information is stored in tables under the gluent_adm schema, such as, tables offloaded, job success, when possible some information on bytes transferred.","title":"Standalone with local repository"},{"location":"2.2.x/install-2.2.x/#full-conductor-for-gluent-with-central-repository","text":"Jobs are configured and scheduled through the front-end software. A single cron job is required to handle the launching of jobs based on schedule in the central repository. All information gathered about the job success, partitions offloaded, etc is stored in the central repository.","title":"Full Conductor for Gluent with Central Repository"},{"location":"2.2.x/install-2.2.x/#prerequisites_1","text":"Gluent Software Installed Cloudera with Impala only parquet-tools available in the path of the edge node for the ssh user when using Full Conductor for Gluent Front-end and Back-end with Central Repository - usually found in /var/lib/alternatives. Central Repository Database Installed (see C4G Frontend Setup Guide)","title":"Prerequisites"},{"location":"2.2.x/install-2.2.x/#unpack-software","text":"A tar file will be supplied. The tar file should be unpacked in a directory such as, c4g-scripts or scripts or similar. For example: cd /u01/app/gluent mkdir c4g-scripts cd c4g-scripts tar xf {tar file name}","title":"Unpack Software"},{"location":"2.2.x/install-2.2.x/#environment-file-setup","text":"Note on split configuration : If gluent is setup in a split configuration, then certain scripts will not function, and certain variables are not set in the environment files.","title":"Environment File Setup"},{"location":"2.2.x/install-2.2.x/#conductor_for_gluentenv","text":"A template for the conductor_for_gluent.env file can be found under the env/templates directory - it is recommended that you copy the template file as a starting point. PATH - This export of the path is to make sure the oraenv script is in the path. ORACLE_SID - Set this to the Oracle SID of the database which is being offloaded. ORAENV_ASK - Set for no prompts. oraenv - script to set the oracle environment. Unset ORAENV_ASK As this shell script runs SQL, the SQL_PATH variable is unset, so as not to get possible interference (same name scripts, login.sql files, etc). OFFLOAD_HOME=\"/u01/app/gluent/offload\" - Update OFFLOAD_HOME to the location of the gluent software offload home. . $OFFLOAD_HOME/conf/offload.env - DO NOT CHANGE C4G_REPO NONE - No Repository; standalone mode without a repository RUNTIME- run a local repository that stores information generated a runtime FULL - run a central repository that stores information about jobs, schedules, etc. HADOOP_HOST - defaults to the HDFS_CMD_HOST HADOOP_SSH_USER - set to the target user on hadoop for ssh G_ERROR_WORDS - Words and phrases used when determining if a possible error occurred. TNS_ADMIN - Always set to ${tnsdir} - DO NOT CHANGE AEG_GLUENT_REPO_SERVICE - service name to be used when connecting to the central repository AEG_GLUENT_LOCAL_SERVICE - service name to be used when connecting to the local database dstr - service name used in local repository and standalone mode impala_node - automatically determined but can be overridden IMPALA_SHELL_CMD - command with options need to run impala-shell","title":"conductor_for_gluent.env"},{"location":"2.2.x/install-2.2.x/#run-gluent-jobenv","text":"A template for the file can be found under the env/templates directory - it is recommended that you copy the template file as a starting point. PRECREATED_DBS - true or false (defaults to false) Only add/update if gluent is not allowed to create databases on impala G_BEGIN_NOTIFY - true or false G_BEGIN_MAIL_LIST - email addresses space separated in quotes. G_SUCCESS_NOTIFY - true or false G_SUCCESS_MAIL_LIST - email addresses space separated in quotes. G_ERROR_NOTIFY -true or false G_ERROR_MAIL_LIST - email addresses space separated in quotes.","title":"run-gluent-job.env"},{"location":"2.2.x/install-2.2.x/#setup-walletenv","text":"A template for the file can be found under the env/templates directory - it is recommended that you copy the template file as a starting point. AEG_WALLET_LOCATION=/u01/app/gluent/scripts/tns - update to the location to contain the wallet WALLET_ENTRY - the wallet entry you want to setup (corresponds to a TNS service name)","title":"setup-wallet.env"},{"location":"2.2.x/install-2.2.x/#configuration-file-setup","text":"If not running in the Central Repository mode, then 2 configuration files can be created to set default offload and present parameters. offload-defaults.cfg present-defaults.cfg","title":"Configuration File Setup"},{"location":"2.2.x/install-2.2.x/#user-setup-in-local-database-for-central-repository-mode","text":"A user is needed in the local database with the following username: CONDUCTOR_FOR_GLUENT create user conductor_for_gluent identified by \"{complex password}\" default tablespace users temporary tablespace temp; The privileges needed are: GRANT CONNECT TO CONDUCTOR_FOR_GLUENT; GRANT GLUENT_OFFLOAD_ROLE TO CONDUCTOR_FOR_GLUENT; GRANT SELECT ANY DICTIONARY TO CONDUCTOR_FOR_GLUENT; GRANT SELECT ANY TABLE TO CONDUCTOR_FOR_GLUENT; -- Needed for Conductor for Gluent to do partition maintenance GRANT DROP ANY TABLE TO CONDUCTOR_FOR_GLUENT; GRANT ALTER ANY TABLE TO CONDUCTOR_FOR_GLUENT; An alternative to the ANY TABLE privilege is to preform the grant(s) on the tables to be offloaded.","title":"User Setup in Local Database for Central Repository Mode"},{"location":"2.2.x/install-2.2.x/#tns-setup","text":"This is needed for all 3 modes of the backend software.","title":"TNS Setup"},{"location":"2.2.x/install-2.2.x/#tnsnamesora","text":"A TNSNAMES.ORA file needs to be created in the tns subdirectory. For the no repository option or the local repository option, one entry for the local DB being offloaded is needed. For the central repository mode, two entries are needed: one for local DB and a second for the central repository. Suggested names are as follows: c4g_local c4g_central Historically, the tns entry was: gluent_conn A sample file is located under the tns/sample directory, showing a simple tns entry.","title":"TNSNAMES.ORA"},{"location":"2.2.x/install-2.2.x/#wallet-setup","text":"For Full Conductor for Gluent, run the following: ./setup-wallet new c4g_local ./setup-wallet add c4g_central For Standalone or Runtime Repository modes, run the following: ./setup-wallet new gluent_conn","title":"Wallet Setup"},{"location":"2.2.x/install-2.2.x/#crontab-setup","text":"Once the backend and frontend software are installed, add a cron entry to run the launch script. The job should be like the following with the appropriate path specified: * * * * * /u01/app/gluent/scripts/bin/launch-gluent-jobs {DB/Container Name} > /u01/app/gluent/scripts/log/launch-gluent-jobs-cron.log 2>&1","title":"Crontab Setup"},{"location":"2.2.x/install-2.2.x/#appendix-a-xdbconfig_anonymoussql","text":"DECLARE l_configxml XMLTYPE; l_value VARCHAR2(5) := 'true'; BEGIN l_configxml := DBMS_XDB.cfg_get(); IF l_configxml.existsNode('/xdbconfig/sysconfig/protocolconfig/httpconfig/allow-repository-anonymous-access') = 0 THEN -- Add config element begin SELECT insertChildXML( l_configxml , '/xdbconfig/sysconfig/protocolconfig/httpconfig' , 'allow-repository-anonymous-access' , XMLType('<allow-repository-anonymous-access xmlns=\"http://xmlns.oracle.com/xdb/xdbconfig.xsd\">' || l_value || '</allow-repository-anonymous-access>') , 'xmlns=\"http://xmlns.oracle.com/xdb/xdbconfig.xsd\"' ) INTO l_configxml FROM dual; exception when others then dbms_output.put_line( 'insert' ); -- ' raise; end; DBMS_OUTPUT.put_line('xdbconfig for anonymous now inserted.'); ELSE -- Update existing config element. begin SELECT updateXML( DBMS_XDB.cfg_get() , '/xdbconfig/sysconfig/protocolconfig/httpconfig/allow-repository-anonymous-access/text()' , XMLType('<allow-repository-anonymous-access xmlns=\"http://xmlns.oracle.com/xdb/xdbconfig.xsd\">' || l_value || '</allow-repository-anonymous-access>') , 'xmlns=\"http://xmlns.oracle.com/xdb/xdbconfig.xsd\"' ) INTO l_configxml FROM dual; exception when others then dbms_output.put_line( 'update'); -- ' raise; end; DBMS_OUTPUT.put_line('xdbconfig for anonymous now updated.'); END IF; DBMS_XDB.cfg_update(l_configxml); DBMS_XDB.cfg_refresh; END; /","title":"Appendix A - xdbconfig_anonymous.sql"},{"location":"2.2.x/relnotes/","text":"2.2.12 Table dropdown only shows tables from selected DB Now able to add parameters at table level Key column specification can be edited Transfer details are being gathered on offload Incrmental improvements: error handling wording on a few frontend screens updated charts Upgrade Instructions cd {C4G_INSTALLATION_LOCATION} tar --overwrite -xpf conductor_for_gluent-2.2.11.tar.bz2 export TNS_ADMIN={C4G_INSTALLATION_LOCATION}/tns sqlplus /@{C4G_REPOSITORY_SERVICE_NAME} @install/c4g-update-schema-2.2.12.sql @install/c4g-apex-application.sql @install/c4g-setup-source.sql 2.2.11 Corrected sizing calculation with Oracle, Hadoop, Elgible, Dropped bars on all charts Table names will now only show for current database instead of all databases Corrected query sort order on Bytes Comparison and Space Recovery charts on the dashboard Corrected problem in output from the get_col_spec_details procedure Corrected issue with offload details not being collected Incremental improvements to the frontend, including: Color conisistency for charts Column sort available on dataset (partition) reports Auto-refresh on dashboard Percent completion on job list Upgrade Instructions cd {C4G_INSTALLATION_LOCATION} tar --overwrite -xpf conductor_for_gluent-2.2.11.tar.bz2 export TNS_ADMIN={C4G_INSTALLATION_LOCATION}/tns sqlplus /@{C4G_REPOSITORY_SERVICE_NAME} @install/c4g-update-schema-2.2.11.sql @install/c4g-apex-application.sql @install/c4g-setup-source.sql 2.2.10 Change to directory/file structure and naming: gui renamed to install all templates for files have been placed in a templates subdirectory in respective location for consistency Corrected issue where column partitioning information was not being gathered on a duplicate job types Incremental improvements to the frontend Upgrade Instructions cd {C4G_INSTALLATION_LOCATION}/.. mv {C4G_INSTALLATION_LOCATION} {C4G_INSTALLATION_LOCATION}. date +\"%Y%m%d\" tar -xpf conductor_for_gluent-2.2.10.tar.bz2 cp {C4G_INSTALLATION_LOCATION}. date/tns/*.ora {C4G_INSTALLATION_LOCATION}. date/tns/. cp {C4G_INSTALLATION_LOCATION}. date/tns/*wallet* {C4G_INSTALLATION_LOCATION}. date/tns/. cp {C4G_INSTALLATION_LOCATION}. date/env/*.env {C4G_INSTALLATION_LOCATION}. date/env/. export TNS_ADMIN={C4G_INSTALLATION_LOCATION}/tns sqlplus /@{C4G_REPOSITORY_SERVICE_NAME} @install/c4g-apex-application.sql @install/c4g-setup-source.sql 2.2.9 Changes to database interaction to have it be a co-process (only connect once to database) Upgrade Instructions cd {C4G_INSTALLATION_LOCATION} tar -xf conductor_for_gluent-upgrade-2.2.9.tar.bz2 sqlplus conductor_for_gluent/{password}@{C4G_REPOSITORY_SERVICE_NAME} @gui/c4g-apex-application.sql @gui/c4g-setup-source.sql 2.2.8 Optimization of some SQL calls Improvements in help text Upgrade Instructions cd {C4G_INSTALLATION_LOCATION} tar -xf conductor_for_gluent-upgrade-2.2.8.tar.bz2 sqlplus conductor_for_gluent/{password}@{C4G_REPOSITORY_SERVICE_NAME} @gui/c4g-apex-application.sql @gui/c4g-setup-source.sql @gui/c4g-setup-helptext.sql 2.2.7 Changed DB Details Apex screen to handle loopback connection for DB LINK Changed Incremental Update Flag from a selection dropdown to an autocomplete text field Fixed issue with database level parameters not being included in offload/present commands Reduced length of variable name to less than 30 characters Corrected issue with job not exiting on error in certain cases Upgrade Instructions cd {C4G_INSTALLATION_LOCATION} tar -xf conductor_for_gluent-upgrade-2.2.7.tar.bz2 sqlplus conductor_for_gluent/{password}@{C4G_REPOSITORY_SERVICE_NAME} @gui/c4g-apex-application.sql @gui/c4g-setup-source.sql 2.2.6 Add license/copyright info 2.2.5 Corrected command parameters, so they take into account gluent version at DB, Table and Job Step levels Add feature to limit cmd parameters that show at Site and DB levels that do not make sense (e.g. ones that specify columns) Command parameters are available for Gluent versions 2.11 - 3.4 launch-guent-job updated so it will only attempt to launch jobs for its database install Continued improvement the processing when recording information about Oracle and Hadoop Datasets Improvements to debug mode and logging 2.2.3 Incremental improvment in the processing details about Oracle Datasets 2.2.2 Lengthen columns from 30 to 128 for long naming support Correct issue in calendar GUI improvements 2.2.1 Renamed table and associated objects to get the length of them to fit in 30 characters. 2.2.0 Ability to add a new table adhawk rather than uploading an advisor report Column making works on char/varchar2 data types A generate drop statements or actual drop statements can be scheduled as a job step for partition maintenance of offloaded table data based on a Drop Threshold. GENERATE option added to OFFLOAD_DROP_ACTION application parameter to generate drop partition statements but not run them. Added column to Oracle Dataset Report that shows which partitions are eligible for dropping Metrics added on the Site Home and Database Home screens Known Issues Composite Partitions Keys do not work properly for the partition maintenance features. 2.1.3 Template Files updated to correctly reflect the changes in environment variables in release 2.1.0 Help Text installation is working without manual intervention Documentation Website added - https://swnerd.github.io/c4g-doc/","title":"Release Notes"},{"location":"2.2.x/relnotes/#2212","text":"Table dropdown only shows tables from selected DB Now able to add parameters at table level Key column specification can be edited Transfer details are being gathered on offload Incrmental improvements: error handling wording on a few frontend screens updated charts","title":"2.2.12"},{"location":"2.2.x/relnotes/#upgrade-instructions","text":"cd {C4G_INSTALLATION_LOCATION} tar --overwrite -xpf conductor_for_gluent-2.2.11.tar.bz2 export TNS_ADMIN={C4G_INSTALLATION_LOCATION}/tns sqlplus /@{C4G_REPOSITORY_SERVICE_NAME} @install/c4g-update-schema-2.2.12.sql @install/c4g-apex-application.sql @install/c4g-setup-source.sql","title":"Upgrade Instructions"},{"location":"2.2.x/relnotes/#2211","text":"Corrected sizing calculation with Oracle, Hadoop, Elgible, Dropped bars on all charts Table names will now only show for current database instead of all databases Corrected query sort order on Bytes Comparison and Space Recovery charts on the dashboard Corrected problem in output from the get_col_spec_details procedure Corrected issue with offload details not being collected Incremental improvements to the frontend, including: Color conisistency for charts Column sort available on dataset (partition) reports Auto-refresh on dashboard Percent completion on job list","title":"2.2.11"},{"location":"2.2.x/relnotes/#upgrade-instructions_1","text":"cd {C4G_INSTALLATION_LOCATION} tar --overwrite -xpf conductor_for_gluent-2.2.11.tar.bz2 export TNS_ADMIN={C4G_INSTALLATION_LOCATION}/tns sqlplus /@{C4G_REPOSITORY_SERVICE_NAME} @install/c4g-update-schema-2.2.11.sql @install/c4g-apex-application.sql @install/c4g-setup-source.sql","title":"Upgrade Instructions"},{"location":"2.2.x/relnotes/#2210","text":"Change to directory/file structure and naming: gui renamed to install all templates for files have been placed in a templates subdirectory in respective location for consistency Corrected issue where column partitioning information was not being gathered on a duplicate job types Incremental improvements to the frontend","title":"2.2.10"},{"location":"2.2.x/relnotes/#upgrade-instructions_2","text":"cd {C4G_INSTALLATION_LOCATION}/.. mv {C4G_INSTALLATION_LOCATION} {C4G_INSTALLATION_LOCATION}. date +\"%Y%m%d\" tar -xpf conductor_for_gluent-2.2.10.tar.bz2 cp {C4G_INSTALLATION_LOCATION}. date/tns/*.ora {C4G_INSTALLATION_LOCATION}. date/tns/. cp {C4G_INSTALLATION_LOCATION}. date/tns/*wallet* {C4G_INSTALLATION_LOCATION}. date/tns/. cp {C4G_INSTALLATION_LOCATION}. date/env/*.env {C4G_INSTALLATION_LOCATION}. date/env/. export TNS_ADMIN={C4G_INSTALLATION_LOCATION}/tns sqlplus /@{C4G_REPOSITORY_SERVICE_NAME} @install/c4g-apex-application.sql @install/c4g-setup-source.sql","title":"Upgrade Instructions"},{"location":"2.2.x/relnotes/#229","text":"Changes to database interaction to have it be a co-process (only connect once to database)","title":"2.2.9"},{"location":"2.2.x/relnotes/#upgrade-instructions_3","text":"cd {C4G_INSTALLATION_LOCATION} tar -xf conductor_for_gluent-upgrade-2.2.9.tar.bz2 sqlplus conductor_for_gluent/{password}@{C4G_REPOSITORY_SERVICE_NAME} @gui/c4g-apex-application.sql @gui/c4g-setup-source.sql","title":"Upgrade Instructions"},{"location":"2.2.x/relnotes/#228","text":"Optimization of some SQL calls Improvements in help text","title":"2.2.8"},{"location":"2.2.x/relnotes/#upgrade-instructions_4","text":"cd {C4G_INSTALLATION_LOCATION} tar -xf conductor_for_gluent-upgrade-2.2.8.tar.bz2 sqlplus conductor_for_gluent/{password}@{C4G_REPOSITORY_SERVICE_NAME} @gui/c4g-apex-application.sql @gui/c4g-setup-source.sql @gui/c4g-setup-helptext.sql","title":"Upgrade Instructions"},{"location":"2.2.x/relnotes/#227","text":"Changed DB Details Apex screen to handle loopback connection for DB LINK Changed Incremental Update Flag from a selection dropdown to an autocomplete text field Fixed issue with database level parameters not being included in offload/present commands Reduced length of variable name to less than 30 characters Corrected issue with job not exiting on error in certain cases","title":"2.2.7"},{"location":"2.2.x/relnotes/#upgrade-instructions_5","text":"cd {C4G_INSTALLATION_LOCATION} tar -xf conductor_for_gluent-upgrade-2.2.7.tar.bz2 sqlplus conductor_for_gluent/{password}@{C4G_REPOSITORY_SERVICE_NAME} @gui/c4g-apex-application.sql @gui/c4g-setup-source.sql","title":"Upgrade Instructions"},{"location":"2.2.x/relnotes/#226","text":"Add license/copyright info","title":"2.2.6"},{"location":"2.2.x/relnotes/#225","text":"Corrected command parameters, so they take into account gluent version at DB, Table and Job Step levels Add feature to limit cmd parameters that show at Site and DB levels that do not make sense (e.g. ones that specify columns) Command parameters are available for Gluent versions 2.11 - 3.4 launch-guent-job updated so it will only attempt to launch jobs for its database install Continued improvement the processing when recording information about Oracle and Hadoop Datasets Improvements to debug mode and logging","title":"2.2.5"},{"location":"2.2.x/relnotes/#223","text":"Incremental improvment in the processing details about Oracle Datasets","title":"2.2.3"},{"location":"2.2.x/relnotes/#222","text":"Lengthen columns from 30 to 128 for long naming support Correct issue in calendar GUI improvements","title":"2.2.2"},{"location":"2.2.x/relnotes/#221","text":"Renamed table and associated objects to get the length of them to fit in 30 characters.","title":"2.2.1"},{"location":"2.2.x/relnotes/#220","text":"Ability to add a new table adhawk rather than uploading an advisor report Column making works on char/varchar2 data types A generate drop statements or actual drop statements can be scheduled as a job step for partition maintenance of offloaded table data based on a Drop Threshold. GENERATE option added to OFFLOAD_DROP_ACTION application parameter to generate drop partition statements but not run them. Added column to Oracle Dataset Report that shows which partitions are eligible for dropping Metrics added on the Site Home and Database Home screens","title":"2.2.0"},{"location":"2.2.x/relnotes/#known-issues","text":"Composite Partitions Keys do not work properly for the partition maintenance features.","title":"Known Issues"},{"location":"2.2.x/relnotes/#213","text":"Template Files updated to correctly reflect the changes in environment variables in release 2.1.0 Help Text installation is working without manual intervention Documentation Website added - https://swnerd.github.io/c4g-doc/","title":"2.1.3"},{"location":"2.2.x/user-guide-2.2.x/","text":"Introduction Conductor for Gluent is an application to help manage Gluent offloads. The Gluent software works on a per database basis. Conductor has an additional unit above a database called a site. A particular installation of Conductor will have one site with one or more databases to manage. Login Enter the Conductor for Gluent Apex URL into your browser. The URL will be something of the form: http://{hostname}:{port}/apex/f?p=100 Once the Conductor for Gluent login form is available, then enter your username and password for Conductor for Gluent. Site For Conductor, a site is made up of multiple databases. Site Home Page From the site home: You can manage site level options: Default Offload Parameters Default Present Parameters Site Level Notification Options Application Defaults Review metrics at the site level: Job Metrics Amount of Data Offloaded Amount of Space that hasn't been selected from the Gluent Advisor Report Add a New Database - Click on the Add New card from the list. Select a Database to Manage - Click on one of the database cards, to manage its jobs and tables. Edit the details of a database - Click on the Edit Link of a database to change its description, icon color, database link information, etc. Site Level Offload Parameters Parameters listed here will be used for every offload command executed across all the databases. Any common or offload type parameter can be added; however, there are few parameters that you would want to apply to all of your offloads. The only example that I have come across was the use of the parameter \"--count-star-expression\". Site Level Present Parameters Parameters listed here will be used for every present command across all the databases. Any common or present type parameter can be added; however, there are few parameters that you would want to apply to all of your present commands. Site Level Notifications Options The implementation of notifications is different than that of parameters. For notifications, the job notifications override the database notifications which override the site notifications. Values entered at the site level will be used when there are no notifications at the database level and at the job level. Notifications are sent at the following points of a job: When Job Begins When Job Succeeds When Job has an Error Notifications can be enabled and disabled. Site Level Application Defaults The application defaults are parameters that affect the way the Conductor for Gluent functions. Here is a list of the parameters and how they work: JOB_LAUNCH_INTERVAL \u2013 Controls the granularity of the drop down for minutes in the job scheduler. If set to 1, you can specify any minute of the hour (0-59). If you specify 15, you can specify 0, 15, 30, 45. OFFLOAD_DROP_RATIO \u2013 Controls the default value for the DROP_THRESHOLD on tables. The value in this field will be multiplied with the OFFLOAD_THRESHOLD to determine the default for the DROP_THRESHOLD. CREATE_HADOOP_DB \u2013 Controls whether the parameter \u2013create-hadoop-db will be included on offload commands. If the Hadoop cluster allows the gluent user to create databases, then it should be set to YES. If the Hadoop cluster does not allow the gluent user to create databases, then set to NO. OFFLOAD_DROP_ACTION \u2013 This is the site-wide default for whether an offload job step should attempt to GENERATE : Generate a script to drop the offloaded partitions after an offload is completed based on Drop Threshold. AUTO : Drop the offloaded partitions after a table is offload based on Drop Threshold. MANUAL : Do Nothing after offload is completed. The OFFLOAD_DROP_ACTION can be over-ridden at the table level. Add/Edit Database The database name, description and connection method can be specified on this screen. Then press Add button. To update the database link information (if that is being used), is done by pressing on the DB Link Wizard button. DB Link Wizard \u2013 Step 1 Enter the host name, port, service name, and password. Press Next to create the database link. DB Link Wizard \u2013 Step 2 Press Test DB Link to verify that the database link is correct. Press Finish if the test is successful. Press the left arrow to go back and correct any of the database link information. Database Database Home Page After clicking on a database on the Site Home, you will go to the database home page for that particular database. At the top of the screen are buttons/links to set offload, present and notification parameters at the database level Followed by some summary information about the database: Advisor Candidates \u2013 # of tables in the advisor report that have not been selected for offload. Select Tables \u2013 # of tables that have been selected as candidates for offload. Total Jobs \u2013 # of jobs that have been created. Running Jobs \u2013 # of jobs currently running. Successful Jobs \u2013 # of jobs that completed successfully. Jobs in Error State \u2013 # of jobs where an error has occurred. Below you will find metrics at the database level for the selected database: Job Metrics Amount of Data Offloaded Amount of Space that hasn't been selected from the Gluent Advisor Report From this page, the menu options expand to include access to: Dashboard Job Maintenance Table Review Candidate Selection DB Level Offload Parameters Parameters listed here will be used for every offload command executed for this database. Any common or offload type parameter can be added; however, there are few parameters that you would want to apply to all of your database offloads. DB Level Present Parameters Parameters listed here will be used for every present command executed for this database. Any common or present type parameter can be added; however, there are few parameters that you would want to apply to all of your database present commands. DB Level Notifications Options The implementation of notifications is different than that of parameters. For notifications, the job notifications override the database notifications which override the site notifications. Values entered at the database level will be used when there are no notifications at the job level. Notifications are sent at the following points of a job: When Job Begins When Job Succeeds When Job has an Error Notifications can be enabled and disabled. Tables Candidate Selection Wizard Step 1 \u2013 Select an Advisor Output File : Select a file or if this is your second time through, you can use the existing file. Multiple files can be uploaded if a new advisor report CSV is obtained. Press Next to continue. Step 2 \u2013 Select Tables : Select one or more tables that you want to offload. Press Next to continue. Step 3 \u2013 Table Thresholds : The default offload threshold will be determined from the Advisor report. The drop threshold default will be calculated using the application parameter OFFLOAD_DROP_RATIO * offload threshold. Either threshold may be updated if desired. Press Next to continue. Step 4 \u2013 Partition Details : If a database link is in use, then the partition details will be automatically loaded from the database into the repository. If no connection is available, the partition details will need to be entered manually. Additionally, a column mask can be selected for numbers or strings that represent dates. Press Finish to complete the wizard. Table Review The table review screen allows you to add a new table and view information about the tables that have been selected to offload. The following details about tables are available: For all tables, you can: View and Update table level offload parameters Review the Oracle Offload Datasets Review the Hadoop Offload Datasets Additionally, for partitioned tables, you can: View and update the partition details View and update the offload and drop threshold, as well as, the offload drop action. Add Table Wizard To add a new table, click the Add Table Wizard button. When a database link is allowed, the first screen of the Add Table Wizard will have select lists for the schemas and table names. When next is hit, the partitioning information will be automatically gathered. When no connection is allowed, you will need to manually enter the correct schema, table_name and partitioning type. The second screen of the Add Table Wizard will be used to specify the Offload and Drop Thresholds for partition tables. No information is entered for non-partitioned tables. The third screen of the Add Table Wizard is used to specify the partition keys when no connection is allowed. Plus, date masking can be specified for cases where a string or number is used to represent a date. No information is entered for non-partitioned tables. Jobs Job Maintenance Main Screen The main screen for job maintenance contains cards, each with a job on it. Jobs can be selected by clicking on the card. Clicking on the current card allows the editing of details about the job. The job steps are editable in this screen. The Job Add Wizard and calendar view are available by pressing the corresponding buttons. Jobs - Duplicate Table Job Configuration When there are duplicate copies of tables that need to be offloaded in multiple schemas. An example of this would be if a company had a schema per client with the same tables under each schema. A Duplicate Table Job is added through the Add Job Wizard , however, only step 1 is entered. After completing step 1, you will be taken back to the main job maintenance screen. Once you select the job, you can start adding elements to the configuration. The different types of elements in a configuration are: Duplicate Enter duplicate table details. Only a table name is specified (no schema/owner), as there are multiple duplicate tables across the database The duplicate element will look for the specified table name across all schemas in the database. Include Enter the details for a specific table that should be included in the job. Enter a full table name with owner/schema and table names specified. Exclude Enter the details for a specific table that should be excluded in the job. Enter a full table name with owner/schema and table names specified. Example A call center company has one schema for each client that they service through their call center. Under each of those client schemas, they have a CALL_DETAILS table which needs to be offload. In addition, they have a training schema, which has a CALL_DETAILS table that should not be offloaded. The configuration elements for this scenario are: Duplicate, CALL_DETAILS Exclude, TRAINING.CALL_DETAILS This will result in a job being geneated based on the frequency desired that will have all of the CALL_DETAILS tables except the one from the TRAINING schema. Add Job Wizard Step 1: Job Name and Type The job name can be any alpha-numeric characters. The job description is a free form field. The job type is going to be Normal most of the time. Press Next to continue. Note: A rare case calls for a Duplicate Table job type, when there are duplicate copies of tables that need to be offloaded in multiple schemas. An example of this would be if a company had a schema per client with the same tables under each schema. A Duplicate Table job does not have defined steps. This job type will be covered in a separate section. Step 2: Job Steps Select the step type. Then select the table for the step. Select if the step is enabled or disabled. All steps also have a step comment. Other fields will depend on the step type. Press Next to continue. Step 3: Job Schedule Jobs can be scheduled on a Monthly, Weekly, Daily, or Hourly basis. With each, you must select the appropriate details: Monthly \u2013 day of the month (1-28), hour and minute Weekly \u2013 day of the week, hour and minute Daily \u2013 hour and minute Hourly \u2013 minute Only jobs with complete information can be enabled. Jobs - Future Calendar Based on the job scheduling information that has been entered, you can view when jobs will run to help see when there might be conflicts with a maintenance outage or too many jobs running at once. Dashboard The dashboard allows for monitoring of running jobs and shows some statistics on offloaded tables. Job States The donut graph shows a summary by state of the jobs. The state pieces can be clicked on to drill down into the details. Recent Jobs The 10 most recent jobs. Drilldown to the Current Run of the Job, by clicking on the ID. Also, the job name can be selected to drill down to the job details. Bytes Comparison Bytes used in Impala versus the bytes used in Oracle Space Recovery In orange is the amount of space that could be recovered if data was truncated/dropped from the offload partitions. In red, we have the amount of data that was truncated/dropped from oracle after offload.","title":"User Guide"},{"location":"2.2.x/user-guide-2.2.x/#introduction","text":"Conductor for Gluent is an application to help manage Gluent offloads. The Gluent software works on a per database basis. Conductor has an additional unit above a database called a site. A particular installation of Conductor will have one site with one or more databases to manage.","title":"Introduction"},{"location":"2.2.x/user-guide-2.2.x/#login","text":"Enter the Conductor for Gluent Apex URL into your browser. The URL will be something of the form: http://{hostname}:{port}/apex/f?p=100 Once the Conductor for Gluent login form is available, then enter your username and password for Conductor for Gluent.","title":"Login"},{"location":"2.2.x/user-guide-2.2.x/#site","text":"For Conductor, a site is made up of multiple databases.","title":"Site"},{"location":"2.2.x/user-guide-2.2.x/#site-home-page","text":"From the site home: You can manage site level options: Default Offload Parameters Default Present Parameters Site Level Notification Options Application Defaults Review metrics at the site level: Job Metrics Amount of Data Offloaded Amount of Space that hasn't been selected from the Gluent Advisor Report Add a New Database - Click on the Add New card from the list. Select a Database to Manage - Click on one of the database cards, to manage its jobs and tables. Edit the details of a database - Click on the Edit Link of a database to change its description, icon color, database link information, etc.","title":"Site Home Page"},{"location":"2.2.x/user-guide-2.2.x/#site-level-offload-parameters","text":"Parameters listed here will be used for every offload command executed across all the databases. Any common or offload type parameter can be added; however, there are few parameters that you would want to apply to all of your offloads. The only example that I have come across was the use of the parameter \"--count-star-expression\".","title":"Site Level Offload Parameters"},{"location":"2.2.x/user-guide-2.2.x/#site-level-present-parameters","text":"Parameters listed here will be used for every present command across all the databases. Any common or present type parameter can be added; however, there are few parameters that you would want to apply to all of your present commands.","title":"Site Level Present Parameters"},{"location":"2.2.x/user-guide-2.2.x/#site-level-notifications-options","text":"The implementation of notifications is different than that of parameters. For notifications, the job notifications override the database notifications which override the site notifications. Values entered at the site level will be used when there are no notifications at the database level and at the job level. Notifications are sent at the following points of a job: When Job Begins When Job Succeeds When Job has an Error Notifications can be enabled and disabled.","title":"Site Level Notifications Options"},{"location":"2.2.x/user-guide-2.2.x/#site-level-application-defaults","text":"The application defaults are parameters that affect the way the Conductor for Gluent functions. Here is a list of the parameters and how they work: JOB_LAUNCH_INTERVAL \u2013 Controls the granularity of the drop down for minutes in the job scheduler. If set to 1, you can specify any minute of the hour (0-59). If you specify 15, you can specify 0, 15, 30, 45. OFFLOAD_DROP_RATIO \u2013 Controls the default value for the DROP_THRESHOLD on tables. The value in this field will be multiplied with the OFFLOAD_THRESHOLD to determine the default for the DROP_THRESHOLD. CREATE_HADOOP_DB \u2013 Controls whether the parameter \u2013create-hadoop-db will be included on offload commands. If the Hadoop cluster allows the gluent user to create databases, then it should be set to YES. If the Hadoop cluster does not allow the gluent user to create databases, then set to NO. OFFLOAD_DROP_ACTION \u2013 This is the site-wide default for whether an offload job step should attempt to GENERATE : Generate a script to drop the offloaded partitions after an offload is completed based on Drop Threshold. AUTO : Drop the offloaded partitions after a table is offload based on Drop Threshold. MANUAL : Do Nothing after offload is completed. The OFFLOAD_DROP_ACTION can be over-ridden at the table level.","title":"Site Level Application Defaults"},{"location":"2.2.x/user-guide-2.2.x/#addedit-database","text":"The database name, description and connection method can be specified on this screen. Then press Add button. To update the database link information (if that is being used), is done by pressing on the DB Link Wizard button.","title":"Add/Edit Database"},{"location":"2.2.x/user-guide-2.2.x/#db-link-wizard-step-1","text":"Enter the host name, port, service name, and password. Press Next to create the database link.","title":"DB Link Wizard \u2013 Step 1"},{"location":"2.2.x/user-guide-2.2.x/#db-link-wizard-step-2","text":"Press Test DB Link to verify that the database link is correct. Press Finish if the test is successful. Press the left arrow to go back and correct any of the database link information.","title":"DB Link Wizard \u2013 Step 2"},{"location":"2.2.x/user-guide-2.2.x/#database","text":"","title":"Database"},{"location":"2.2.x/user-guide-2.2.x/#database-home-page","text":"After clicking on a database on the Site Home, you will go to the database home page for that particular database. At the top of the screen are buttons/links to set offload, present and notification parameters at the database level Followed by some summary information about the database: Advisor Candidates \u2013 # of tables in the advisor report that have not been selected for offload. Select Tables \u2013 # of tables that have been selected as candidates for offload. Total Jobs \u2013 # of jobs that have been created. Running Jobs \u2013 # of jobs currently running. Successful Jobs \u2013 # of jobs that completed successfully. Jobs in Error State \u2013 # of jobs where an error has occurred. Below you will find metrics at the database level for the selected database: Job Metrics Amount of Data Offloaded Amount of Space that hasn't been selected from the Gluent Advisor Report From this page, the menu options expand to include access to: Dashboard Job Maintenance Table Review Candidate Selection","title":"Database Home Page"},{"location":"2.2.x/user-guide-2.2.x/#db-level-offload-parameters","text":"Parameters listed here will be used for every offload command executed for this database. Any common or offload type parameter can be added; however, there are few parameters that you would want to apply to all of your database offloads.","title":"DB Level Offload Parameters"},{"location":"2.2.x/user-guide-2.2.x/#db-level-present-parameters","text":"Parameters listed here will be used for every present command executed for this database. Any common or present type parameter can be added; however, there are few parameters that you would want to apply to all of your database present commands.","title":"DB Level Present Parameters"},{"location":"2.2.x/user-guide-2.2.x/#db-level-notifications-options","text":"The implementation of notifications is different than that of parameters. For notifications, the job notifications override the database notifications which override the site notifications. Values entered at the database level will be used when there are no notifications at the job level. Notifications are sent at the following points of a job: When Job Begins When Job Succeeds When Job has an Error Notifications can be enabled and disabled.","title":"DB Level Notifications Options"},{"location":"2.2.x/user-guide-2.2.x/#tables","text":"","title":"Tables"},{"location":"2.2.x/user-guide-2.2.x/#candidate-selection-wizard","text":"Step 1 \u2013 Select an Advisor Output File : Select a file or if this is your second time through, you can use the existing file. Multiple files can be uploaded if a new advisor report CSV is obtained. Press Next to continue. Step 2 \u2013 Select Tables : Select one or more tables that you want to offload. Press Next to continue. Step 3 \u2013 Table Thresholds : The default offload threshold will be determined from the Advisor report. The drop threshold default will be calculated using the application parameter OFFLOAD_DROP_RATIO * offload threshold. Either threshold may be updated if desired. Press Next to continue. Step 4 \u2013 Partition Details : If a database link is in use, then the partition details will be automatically loaded from the database into the repository. If no connection is available, the partition details will need to be entered manually. Additionally, a column mask can be selected for numbers or strings that represent dates. Press Finish to complete the wizard.","title":"Candidate Selection Wizard"},{"location":"2.2.x/user-guide-2.2.x/#table-review","text":"The table review screen allows you to add a new table and view information about the tables that have been selected to offload. The following details about tables are available: For all tables, you can: View and Update table level offload parameters Review the Oracle Offload Datasets Review the Hadoop Offload Datasets Additionally, for partitioned tables, you can: View and update the partition details View and update the offload and drop threshold, as well as, the offload drop action.","title":"Table Review"},{"location":"2.2.x/user-guide-2.2.x/#add-table-wizard","text":"To add a new table, click the Add Table Wizard button. When a database link is allowed, the first screen of the Add Table Wizard will have select lists for the schemas and table names. When next is hit, the partitioning information will be automatically gathered. When no connection is allowed, you will need to manually enter the correct schema, table_name and partitioning type. The second screen of the Add Table Wizard will be used to specify the Offload and Drop Thresholds for partition tables. No information is entered for non-partitioned tables. The third screen of the Add Table Wizard is used to specify the partition keys when no connection is allowed. Plus, date masking can be specified for cases where a string or number is used to represent a date. No information is entered for non-partitioned tables.","title":"Add Table Wizard"},{"location":"2.2.x/user-guide-2.2.x/#jobs","text":"","title":"Jobs"},{"location":"2.2.x/user-guide-2.2.x/#job-maintenance-main-screen","text":"The main screen for job maintenance contains cards, each with a job on it. Jobs can be selected by clicking on the card. Clicking on the current card allows the editing of details about the job. The job steps are editable in this screen. The Job Add Wizard and calendar view are available by pressing the corresponding buttons.","title":"Job Maintenance Main Screen"},{"location":"2.2.x/user-guide-2.2.x/#jobs-duplicate-table-job-configuration","text":"When there are duplicate copies of tables that need to be offloaded in multiple schemas. An example of this would be if a company had a schema per client with the same tables under each schema. A Duplicate Table Job is added through the Add Job Wizard , however, only step 1 is entered. After completing step 1, you will be taken back to the main job maintenance screen. Once you select the job, you can start adding elements to the configuration. The different types of elements in a configuration are: Duplicate Enter duplicate table details. Only a table name is specified (no schema/owner), as there are multiple duplicate tables across the database The duplicate element will look for the specified table name across all schemas in the database. Include Enter the details for a specific table that should be included in the job. Enter a full table name with owner/schema and table names specified. Exclude Enter the details for a specific table that should be excluded in the job. Enter a full table name with owner/schema and table names specified. Example A call center company has one schema for each client that they service through their call center. Under each of those client schemas, they have a CALL_DETAILS table which needs to be offload. In addition, they have a training schema, which has a CALL_DETAILS table that should not be offloaded. The configuration elements for this scenario are: Duplicate, CALL_DETAILS Exclude, TRAINING.CALL_DETAILS This will result in a job being geneated based on the frequency desired that will have all of the CALL_DETAILS tables except the one from the TRAINING schema.","title":"Jobs - Duplicate Table Job Configuration"},{"location":"2.2.x/user-guide-2.2.x/#add-job-wizard","text":"Step 1: Job Name and Type The job name can be any alpha-numeric characters. The job description is a free form field. The job type is going to be Normal most of the time. Press Next to continue. Note: A rare case calls for a Duplicate Table job type, when there are duplicate copies of tables that need to be offloaded in multiple schemas. An example of this would be if a company had a schema per client with the same tables under each schema. A Duplicate Table job does not have defined steps. This job type will be covered in a separate section. Step 2: Job Steps Select the step type. Then select the table for the step. Select if the step is enabled or disabled. All steps also have a step comment. Other fields will depend on the step type. Press Next to continue. Step 3: Job Schedule Jobs can be scheduled on a Monthly, Weekly, Daily, or Hourly basis. With each, you must select the appropriate details: Monthly \u2013 day of the month (1-28), hour and minute Weekly \u2013 day of the week, hour and minute Daily \u2013 hour and minute Hourly \u2013 minute Only jobs with complete information can be enabled.","title":"Add Job Wizard"},{"location":"2.2.x/user-guide-2.2.x/#jobs-future-calendar","text":"Based on the job scheduling information that has been entered, you can view when jobs will run to help see when there might be conflicts with a maintenance outage or too many jobs running at once.","title":"Jobs - Future Calendar"},{"location":"2.2.x/user-guide-2.2.x/#dashboard","text":"The dashboard allows for monitoring of running jobs and shows some statistics on offloaded tables. Job States The donut graph shows a summary by state of the jobs. The state pieces can be clicked on to drill down into the details. Recent Jobs The 10 most recent jobs. Drilldown to the Current Run of the Job, by clicking on the ID. Also, the job name can be selected to drill down to the job details. Bytes Comparison Bytes used in Impala versus the bytes used in Oracle Space Recovery In orange is the amount of space that could be recovered if data was truncated/dropped from the offload partitions. In red, we have the amount of data that was truncated/dropped from oracle after offload.","title":"Dashboard"},{"location":"3.0.x/install-3.0.x/","text":"Front-end Installation The frontend installation should be done anytime the central Conductor for Gluent repository will be used along with the Conductor for Gluent Apex application. If using the Conductor for Gluent in the standalone mode, please skip down to the backend installation section. Prerequisites Gluent Data Platform 4.1.0+ Installed Oracle 12.2+ Database (created with DBCA or Manually) 1 Oracle Apex 20.2+ 2 Note 1: : Apex requires that Oracle Text and JVM options be installed. No other options are required. Note 2: : Apex and Conductor for Gluent should be installed into the container database, so be sure to run the alter session command to set the container, e.g., ALTER SESSION SET CONTAINER = XEPDB1. Apex 20.2 Setup Create Tablespace for Apex (if one does not exist) SQL> -- Create Tablespace for Apex - Example create tablespace tbs_apex datafile '/opt/oracle/oradata/XE/XEPDB1/tbs_apex01.dbf' size 100m autoextend on maxsize 1000m; Copy Apex 20.2 and ORDS to database host Example Copy to Oracle User Home scp apex_20.2_en.zip {oracle user}@{db host}:. scp ords-20.4.1.013.1644.zip {oracle user}@{db host}:. Remove Existing Apex Software Remove Apex from database (if necessary) cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- Disable existing EXEC DBMS_XDB.SETHTTPPORT(0); SQL> SQL> -- Remove Apex @apxremov.sql PL/SQL procedure successfully completed. ... ... ... ... ...Application Express Removed ******************************************************************** ** You must exit this SQL*Plus session before running apexins.sql ** ******************************************************************** SQL> exit Move original apex software out of the way cd $ORACLE_HOME mv apex apex.orig Install Apex Unzip Apex 20.2 software example statement if uploaded to user's home directory: cd $ORACLE_HOME unzip ~/apex_20.2_en.zip Install Apex 20.2 in database cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- Runtime install with 4 parms (apex tbs, apex tbs, temp tbs, image loc) @apxrtins.sql tbs_apex tbs_apex temp /i/ ...set_appun.sql PL/SQL procedure successfully completed. ...set_ufrom_and_upgrade.sql PL/SQL procedure successfully completed. ... ... ... ... ... ... ... ... ... ... Thank you for installing Oracle Application Express 20.2.0.00.20 Oracle Application Express is installed in the APEX_200200 schema. The structure of the link to the Application Express administration services is as follows: http://host:port/ords/apex_admin The structure of the link to the Application Express development interface is as follows: http://host:port/ords timing for: Phase 3 (Switch) Elapsed: 00:00:49.96 timing for: Complete Installation Elapsed: 00:06:57.48 PL/SQL procedure successfully completed. Change / Setup Apex Administrator cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- no parameters @apxchpwd.sql ...set_appun.sql ================================================================================ This script can be used to change the password of an Application Express instance administrator. If the user does not yet exist, a user record will be created. ================================================================================ Enter the administrator's username [ADMIN] User \"ADMIN\" does not yet exist and will be created. Enter ADMIN's email [ADMIN] Enter ADMIN's password [] Created instance administrator ADMIN. Apex Rest Configuration cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- no parameters @apex_rest_config.sql PL/SQL procedure successfully completed. ... ... ... ... ... ... ... ... ... ... Session altered. PL/SQL procedure successfully completed. PL/SQL procedure successfully completed. ORDS cd $ORACLE_HOME mkdir apex-ords cd apex-ords unzip ~/ords-20.4.1.013.1644.zip cp -r $ORACLE_HOME/apex/images $ORACLE_HOME/apex-ords/. Sample Installation: java -jar ords.war install advanced Specify the database connection type to use. Enter number for [1] Basic [2] TNS [3] Custom URL [1]: Enter the name of the database server [localhost]: Enter the database listen port [1521]: Enter 1 to specify the database service name, or 2 to specify the database SID [1]: Enter the database service name:xepdb1 Enter 1 if you want to verify/install Oracle REST Data Services schema or 2 to skip this step [1]: Enter the database password for ORDS_PUBLIC_USER: Confirm password: Requires to login with administrator privileges to verify Oracle REST Data Services schema. Enter the administrator username:sys Enter the database password for SYS AS SYSDBA: Confirm password: Connecting to database user: SYS AS SYSDBA url: jdbc:oracle:thin:@//localhost:1521/xepdb1 Retrieving information. Enter the default tablespace for ORDS_METADATA [SYSAUX]:tbs_apex Enter the temporary tablespace for ORDS_METADATA [TEMP]: Enter the default tablespace for ORDS_PUBLIC_USER [SYSAUX]:tbs_apex Enter the temporary tablespace for ORDS_PUBLIC_USER [TEMP]: Enter 1 if you want to use PL/SQL Gateway or 2 to skip this step. If using Oracle Application Express or migrating from mod_plsql then you must enter 1 [1]: Enter the PL/SQL Gateway database user name [APEX_PUBLIC_USER]: Enter the database password for APEX_PUBLIC_USER: Confirm password: Enter 1 to specify passwords for Application Express RESTful Services database users (APEX_LISTENER, APEX_REST_PUBLIC_USER) or 2 to skip this step [1]: Enter the database password for APEX_LISTENER: Confirm password: Enter the database password for APEX_REST_PUBLIC_USER: Confirm password: Enter a number to select a feature to enable: [1] SQL Developer Web (Enables all features) [2] REST Enabled SQL [3] Database API [4] REST Enabled SQL and Database API [5] None Choose [1]:4 2021-03-02T01:24:34.126Z INFO reloaded pools: [] Installing Oracle REST Data Services version 20.4.1.r0131644 ... Log file written to /home/oracle/ords_install_core_2021-03-02_012434_00269.log ... Verified database prerequisites ... Created Oracle REST Data Services proxy user Warning: Nashorn engine is planned to be removed from a future JDK release ... Created Oracle REST Data Services schema ... Granted privileges to Oracle REST Data Services ... Created Oracle REST Data Services database objects ... Log file written to /home/oracle/ords_install_datamodel_2021-03-02_012445_00226.log ... Log file written to /home/oracle/ords_install_apex_2021-03-02_012446_00038.log Completed installation for Oracle REST Data Services version 20.4.1.r0131644. Elapsed time: 00:00:12.8 Starting ORDS in Standalone mode: java -jar ords.war standalone Schema Install Create Tablespace Create tablespace to contain the conductor_for_gluent's repository, for example: create tablespace tbs_c4g datafile '+dg_data' size 100M autoextend on next 1M maxsize 100M; or create tablespace tbs_c4g datafile '/u01/app/oracle/oradata/testinst/tbs_c4g01.dbf' size 100M autoextend on next 1M maxsize 1000M; Create User and Privileges Create user conductor_for_gluent with above tablespace as the default tablespace, for example: create user conductor_for_gluent identified by \"{complex password}\" default tablespace tbs_c4g; alter user conductor_for_gluent quota unlimited on tbs_c4g; grant connect to conductor_for_gluent; grant resource to conductor_for_gluent; grant create database link to conductor_for_gluent; grant create synonym to conductor_for_gluent; grant create view to conductor_for_gluent; grant select any dictionary to conductor_for_gluent; grant select any table to conductor_for_gluent; Install and Setup the Objects The installation SQL scripts are located in install directory where the backend scripts were installed (usually /u01/app/gluent/scripts or /u01/app/gluent/c4g-scripts . From this directory connect to the apex database (usually c4g_central is the tns name to use: You can set your environment to use the tnsnames.ora file you created during the backend setup. For example: cd /u01/app/gluent/c4g-scripts/tns export TNS_ADMIN=`pwd` cd ../install sqlplus /@c4g_central Schema Setup Run the sql, no parameters - 1 prompt for tablespace spool c4g-setup-schema.log @c4g-setup-schema.sql Tablespace: tbs_c4g spool off Source Setup Run the sql, no parameters spool c4g-setup-source.log @c4g-setup-source.sql spool off Seed Data Setup Run the sql, no parameters spool c4g-setup-seeddata.log @c4g-setup-seeddata.sql spool off Help Text Setup Run the sql, no parameters spool c4g-setup-helptext.log @c4g-setup-helptext.sql spool off Apex Application Install cd /u01/app/gluent/c4g-scripts/tns export TNS_ADMIN=`pwd` cd ../install sqlplus system/{complex_password}@c4g_central Create the Workspace SQL> -- run the sql, no parameters @c4g-apex-workspace.sql \"Import\" the runtime app (sql script) SQL> -- run the sql, no parameters @c4g-apex-application.sql Connecting to Conductor for Gluent http://{hostname}:8080/apex/f?p=100:LOGIN_DESKTOP:25119307751525::::: Default Users Admin User: c4g_admin App User: c4g_user Please contact your Conductor for Gluent provider for password. \u2003 Back-end Installation Conductor for Gluent Backend Software Usage Options The Conductor for Gluent Backend (evolved from AEG Gluent Toolkit) has three possible modes of operation: Standalone mode Local repository mode Full Conductor for Gluent Front-end and Back-end with Central Repository The standalone and local repository modes of operation have been around and used in production environments for several years (initial deployment to a production environment in Q1 2017). Enhancements have been done over the subsequent time period, including the local repository mode. The central repository integration with Conductor for Gluent frontend was done in 2019. Standalone No additional software is needed or required. The software just provides a consistent job-oriented method for running gluent offloads. Jobs are setup through flat \"job\" files. Scheduling of the individual jobs requires a cron entry per job. Standalone with local repository Same as standalone. Additionally, some result information is stored in tables under the gluent_adm schema, such as, tables offloaded, job success, when possible some information on bytes transferred. Full Conductor for Gluent with Central Repository Jobs are configured and scheduled through the front-end software. A single cron job is required to handle the launching of jobs based on schedule in the central repository. All information gathered about the job success, partitions offloaded, etc is stored in the central repository. Prerequisites Gluent Data Platform 4.1.0+ Installed Central Repository Database Installed (see C4G Frontend Setup Guide) Unpack Software A tar file will be supplied. The tar file should be unpacked in a directory such as, c4g-scripts or scripts or similar. For example: cd /u01/app/gluent mkdir c4g-scripts cd c4g-scripts tar xf {tar file name} Environment File Setup Note on split configuration : If gluent is setup in a split configuration, then certain scripts will not function, and certain variables are not set in the environment files. conductor_for_gluent.env A template for the conductor_for_gluent.env file can be found under the env/templates directory - it is recommended that you copy the template file as a starting point. PATH - This export of the path is to make sure the oraenv script is in the path. ORACLE_SID - Set this to the Oracle SID of the database which is being offloaded. ORAENV_ASK - Set for no prompts. oraenv - script to set the oracle environment. Unset ORAENV_ASK As this shell script runs SQL, the SQL_PATH variable is unset, so as not to get possible interference (same name scripts, login.sql files, etc). OFFLOAD_HOME=\"/u01/app/gluent/offload\" - Update OFFLOAD_HOME to the location of the gluent software offload home. . $OFFLOAD_HOME/conf/offload.env - DO NOT CHANGE C4G_REPO NONE - No Repository; standalone mode without a repository RUNTIME- run a local repository that stores information generated a runtime FULL - run a central repository that stores information about jobs, schedules, etc. G_ERROR_WORDS - Words and phrases used when determining if a possible error occurred. TNS_ADMIN - Always set to ${tnsdir} - DO NOT CHANGE AEG_GLUENT_REPO_SERVICE - service name to be used when connecting to the central repository AEG_GLUENT_LOCAL_SERVICE - service name to be used when connecting to the local database dstr - service name used in local repository and standalone mode run-gluent-job.env A template for the file can be found under the env/templates directory - it is recommended that you copy the template file as a starting point. PRECREATED_DBS - true or false (defaults to false) Only add/update if gluent is not allowed to create databases on impala G_BEGIN_NOTIFY - true or false G_BEGIN_MAIL_LIST - email addresses space separated in quotes. G_SUCCESS_NOTIFY - true or false G_SUCCESS_MAIL_LIST - email addresses space separated in quotes. G_ERROR_NOTIFY -true or false G_ERROR_MAIL_LIST - email addresses space separated in quotes. setup-wallet.env A template for the file can be found under the env/templates directory - it is recommended that you copy the template file as a starting point. AEG_WALLET_LOCATION=/u01/app/gluent/scripts/tns - update to the location to contain the wallet Configuration File Setup If not running in the Central Repository mode, then 2 configuration files can be created to set default offload and present parameters. offload-defaults.cfg present-defaults.cfg User Setup in Local Database for Central Repository Mode A user is needed in the local database with the following username: CONDUCTOR_FOR_GLUENT create user conductor_for_gluent identified by \"{complex password}\" default tablespace users temporary tablespace temp; The privileges needed are: GRANT CONNECT TO CONDUCTOR_FOR_GLUENT; GRANT GLUENT_OFFLOAD_ROLE TO CONDUCTOR_FOR_GLUENT; GRANT SELECT ANY DICTIONARY TO CONDUCTOR_FOR_GLUENT; GRANT SELECT ANY TABLE TO CONDUCTOR_FOR_GLUENT; -- Needed for Conductor for Gluent to do partition maintenance GRANT DROP ANY TABLE TO CONDUCTOR_FOR_GLUENT; GRANT ALTER ANY TABLE TO CONDUCTOR_FOR_GLUENT; An alternative to the ANY TABLE privilege is to perform the grant(s) on the tables to be offloaded. TNS Setup This is needed for all 3 modes of the backend software. TNSNAMES.ORA A TNSNAMES.ORA file needs to be created in the tns subdirectory. For the no repository option or the local repository option, one entry for the local DB being offloaded is needed. For the central repository mode, two entries are needed: one for local DB and a second for the central repository. Suggested names are as follows: c4g_local c4g_central Historically, the tns entry was: gluent_conn A sample file is located under the tns/sample directory, showing a simple tns entry. Wallet Setup For Full Conductor for Gluent, run the following: ./setup-wallet new c4g_local ./setup-wallet add c4g_central For Standalone or Runtime Repository modes, run the following: ./setup-wallet new gluent_conn Crontab Setup Once the backend and frontend software are installed, add a cron entry to run the launch script. The job should be like the following with the appropriate path specified: * * * * * /u01/app/gluent/scripts/bin/launch-gluent-jobs {DB/Container Name} > /u01/app/gluent/scripts/log/launch-gluent-jobs-cron.log 2>&1","title":"Installation"},{"location":"3.0.x/install-3.0.x/#front-end-installation","text":"The frontend installation should be done anytime the central Conductor for Gluent repository will be used along with the Conductor for Gluent Apex application. If using the Conductor for Gluent in the standalone mode, please skip down to the backend installation section.","title":"Front-end Installation"},{"location":"3.0.x/install-3.0.x/#prerequisites","text":"Gluent Data Platform 4.1.0+ Installed Oracle 12.2+ Database (created with DBCA or Manually) 1 Oracle Apex 20.2+ 2 Note 1: : Apex requires that Oracle Text and JVM options be installed. No other options are required. Note 2: : Apex and Conductor for Gluent should be installed into the container database, so be sure to run the alter session command to set the container, e.g., ALTER SESSION SET CONTAINER = XEPDB1.","title":"Prerequisites"},{"location":"3.0.x/install-3.0.x/#apex-202-setup","text":"Create Tablespace for Apex (if one does not exist) SQL> -- Create Tablespace for Apex - Example create tablespace tbs_apex datafile '/opt/oracle/oradata/XE/XEPDB1/tbs_apex01.dbf' size 100m autoextend on maxsize 1000m;","title":"Apex 20.2 Setup"},{"location":"3.0.x/install-3.0.x/#copy-apex-202-and-ords-to-database-host","text":"Example Copy to Oracle User Home scp apex_20.2_en.zip {oracle user}@{db host}:. scp ords-20.4.1.013.1644.zip {oracle user}@{db host}:.","title":"Copy Apex 20.2 and ORDS to database host"},{"location":"3.0.x/install-3.0.x/#remove-existing-apex-software","text":"Remove Apex from database (if necessary) cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- Disable existing EXEC DBMS_XDB.SETHTTPPORT(0); SQL> SQL> -- Remove Apex @apxremov.sql PL/SQL procedure successfully completed. ... ... ... ... ...Application Express Removed ******************************************************************** ** You must exit this SQL*Plus session before running apexins.sql ** ******************************************************************** SQL> exit Move original apex software out of the way cd $ORACLE_HOME mv apex apex.orig","title":"Remove Existing Apex Software"},{"location":"3.0.x/install-3.0.x/#install-apex","text":"","title":"Install Apex"},{"location":"3.0.x/install-3.0.x/#unzip-apex-202-software","text":"example statement if uploaded to user's home directory: cd $ORACLE_HOME unzip ~/apex_20.2_en.zip","title":"Unzip Apex 20.2 software"},{"location":"3.0.x/install-3.0.x/#install-apex-202-in-database","text":"cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- Runtime install with 4 parms (apex tbs, apex tbs, temp tbs, image loc) @apxrtins.sql tbs_apex tbs_apex temp /i/ ...set_appun.sql PL/SQL procedure successfully completed. ...set_ufrom_and_upgrade.sql PL/SQL procedure successfully completed. ... ... ... ... ... ... ... ... ... ... Thank you for installing Oracle Application Express 20.2.0.00.20 Oracle Application Express is installed in the APEX_200200 schema. The structure of the link to the Application Express administration services is as follows: http://host:port/ords/apex_admin The structure of the link to the Application Express development interface is as follows: http://host:port/ords timing for: Phase 3 (Switch) Elapsed: 00:00:49.96 timing for: Complete Installation Elapsed: 00:06:57.48 PL/SQL procedure successfully completed.","title":"Install Apex 20.2 in database"},{"location":"3.0.x/install-3.0.x/#change-setup-apex-administrator","text":"cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- no parameters @apxchpwd.sql ...set_appun.sql ================================================================================ This script can be used to change the password of an Application Express instance administrator. If the user does not yet exist, a user record will be created. ================================================================================ Enter the administrator's username [ADMIN] User \"ADMIN\" does not yet exist and will be created. Enter ADMIN's email [ADMIN] Enter ADMIN's password [] Created instance administrator ADMIN.","title":"Change / Setup Apex Administrator"},{"location":"3.0.x/install-3.0.x/#apex-rest-configuration","text":"cd $ORACLE_HOME/apex sqlplus / as sysdba SQL> -- no parameters @apex_rest_config.sql PL/SQL procedure successfully completed. ... ... ... ... ... ... ... ... ... ... Session altered. PL/SQL procedure successfully completed. PL/SQL procedure successfully completed.","title":"Apex Rest Configuration"},{"location":"3.0.x/install-3.0.x/#ords","text":"cd $ORACLE_HOME mkdir apex-ords cd apex-ords unzip ~/ords-20.4.1.013.1644.zip cp -r $ORACLE_HOME/apex/images $ORACLE_HOME/apex-ords/. Sample Installation: java -jar ords.war install advanced Specify the database connection type to use. Enter number for [1] Basic [2] TNS [3] Custom URL [1]: Enter the name of the database server [localhost]: Enter the database listen port [1521]: Enter 1 to specify the database service name, or 2 to specify the database SID [1]: Enter the database service name:xepdb1 Enter 1 if you want to verify/install Oracle REST Data Services schema or 2 to skip this step [1]: Enter the database password for ORDS_PUBLIC_USER: Confirm password: Requires to login with administrator privileges to verify Oracle REST Data Services schema. Enter the administrator username:sys Enter the database password for SYS AS SYSDBA: Confirm password: Connecting to database user: SYS AS SYSDBA url: jdbc:oracle:thin:@//localhost:1521/xepdb1 Retrieving information. Enter the default tablespace for ORDS_METADATA [SYSAUX]:tbs_apex Enter the temporary tablespace for ORDS_METADATA [TEMP]: Enter the default tablespace for ORDS_PUBLIC_USER [SYSAUX]:tbs_apex Enter the temporary tablespace for ORDS_PUBLIC_USER [TEMP]: Enter 1 if you want to use PL/SQL Gateway or 2 to skip this step. If using Oracle Application Express or migrating from mod_plsql then you must enter 1 [1]: Enter the PL/SQL Gateway database user name [APEX_PUBLIC_USER]: Enter the database password for APEX_PUBLIC_USER: Confirm password: Enter 1 to specify passwords for Application Express RESTful Services database users (APEX_LISTENER, APEX_REST_PUBLIC_USER) or 2 to skip this step [1]: Enter the database password for APEX_LISTENER: Confirm password: Enter the database password for APEX_REST_PUBLIC_USER: Confirm password: Enter a number to select a feature to enable: [1] SQL Developer Web (Enables all features) [2] REST Enabled SQL [3] Database API [4] REST Enabled SQL and Database API [5] None Choose [1]:4 2021-03-02T01:24:34.126Z INFO reloaded pools: [] Installing Oracle REST Data Services version 20.4.1.r0131644 ... Log file written to /home/oracle/ords_install_core_2021-03-02_012434_00269.log ... Verified database prerequisites ... Created Oracle REST Data Services proxy user Warning: Nashorn engine is planned to be removed from a future JDK release ... Created Oracle REST Data Services schema ... Granted privileges to Oracle REST Data Services ... Created Oracle REST Data Services database objects ... Log file written to /home/oracle/ords_install_datamodel_2021-03-02_012445_00226.log ... Log file written to /home/oracle/ords_install_apex_2021-03-02_012446_00038.log Completed installation for Oracle REST Data Services version 20.4.1.r0131644. Elapsed time: 00:00:12.8 Starting ORDS in Standalone mode: java -jar ords.war standalone","title":"ORDS"},{"location":"3.0.x/install-3.0.x/#schema-install","text":"","title":"Schema Install"},{"location":"3.0.x/install-3.0.x/#create-tablespace","text":"Create tablespace to contain the conductor_for_gluent's repository, for example: create tablespace tbs_c4g datafile '+dg_data' size 100M autoextend on next 1M maxsize 100M; or create tablespace tbs_c4g datafile '/u01/app/oracle/oradata/testinst/tbs_c4g01.dbf' size 100M autoextend on next 1M maxsize 1000M;","title":"Create Tablespace"},{"location":"3.0.x/install-3.0.x/#create-user-and-privileges","text":"Create user conductor_for_gluent with above tablespace as the default tablespace, for example: create user conductor_for_gluent identified by \"{complex password}\" default tablespace tbs_c4g; alter user conductor_for_gluent quota unlimited on tbs_c4g; grant connect to conductor_for_gluent; grant resource to conductor_for_gluent; grant create database link to conductor_for_gluent; grant create synonym to conductor_for_gluent; grant create view to conductor_for_gluent; grant select any dictionary to conductor_for_gluent; grant select any table to conductor_for_gluent;","title":"Create User and Privileges"},{"location":"3.0.x/install-3.0.x/#install-and-setup-the-objects","text":"The installation SQL scripts are located in install directory where the backend scripts were installed (usually /u01/app/gluent/scripts or /u01/app/gluent/c4g-scripts . From this directory connect to the apex database (usually c4g_central is the tns name to use: You can set your environment to use the tnsnames.ora file you created during the backend setup. For example: cd /u01/app/gluent/c4g-scripts/tns export TNS_ADMIN=`pwd` cd ../install sqlplus /@c4g_central","title":"Install and Setup the Objects"},{"location":"3.0.x/install-3.0.x/#schema-setup","text":"Run the sql, no parameters - 1 prompt for tablespace spool c4g-setup-schema.log @c4g-setup-schema.sql Tablespace: tbs_c4g spool off","title":"Schema Setup"},{"location":"3.0.x/install-3.0.x/#source-setup","text":"Run the sql, no parameters spool c4g-setup-source.log @c4g-setup-source.sql spool off","title":"Source Setup"},{"location":"3.0.x/install-3.0.x/#seed-data-setup","text":"Run the sql, no parameters spool c4g-setup-seeddata.log @c4g-setup-seeddata.sql spool off","title":"Seed Data Setup"},{"location":"3.0.x/install-3.0.x/#help-text-setup","text":"Run the sql, no parameters spool c4g-setup-helptext.log @c4g-setup-helptext.sql spool off","title":"Help Text Setup"},{"location":"3.0.x/install-3.0.x/#apex-application-install","text":"cd /u01/app/gluent/c4g-scripts/tns export TNS_ADMIN=`pwd` cd ../install sqlplus system/{complex_password}@c4g_central","title":"Apex Application Install"},{"location":"3.0.x/install-3.0.x/#create-the-workspace","text":"SQL> -- run the sql, no parameters @c4g-apex-workspace.sql","title":"Create the Workspace"},{"location":"3.0.x/install-3.0.x/#import-the-runtime-app-sql-script","text":"SQL> -- run the sql, no parameters @c4g-apex-application.sql","title":"\"Import\" the runtime app (sql script)"},{"location":"3.0.x/install-3.0.x/#connecting-to-conductor-for-gluent","text":"http://{hostname}:8080/apex/f?p=100:LOGIN_DESKTOP:25119307751525::::: Default Users Admin User: c4g_admin App User: c4g_user Please contact your Conductor for Gluent provider for password.","title":"Connecting to Conductor for Gluent"},{"location":"3.0.x/install-3.0.x/#back-end-installation","text":"","title":"Back-end Installation"},{"location":"3.0.x/install-3.0.x/#conductor-for-gluent-backend-software-usage-options","text":"The Conductor for Gluent Backend (evolved from AEG Gluent Toolkit) has three possible modes of operation: Standalone mode Local repository mode Full Conductor for Gluent Front-end and Back-end with Central Repository The standalone and local repository modes of operation have been around and used in production environments for several years (initial deployment to a production environment in Q1 2017). Enhancements have been done over the subsequent time period, including the local repository mode. The central repository integration with Conductor for Gluent frontend was done in 2019.","title":"Conductor for Gluent Backend Software Usage Options"},{"location":"3.0.x/install-3.0.x/#standalone","text":"No additional software is needed or required. The software just provides a consistent job-oriented method for running gluent offloads. Jobs are setup through flat \"job\" files. Scheduling of the individual jobs requires a cron entry per job.","title":"Standalone"},{"location":"3.0.x/install-3.0.x/#standalone-with-local-repository","text":"Same as standalone. Additionally, some result information is stored in tables under the gluent_adm schema, such as, tables offloaded, job success, when possible some information on bytes transferred.","title":"Standalone with local repository"},{"location":"3.0.x/install-3.0.x/#full-conductor-for-gluent-with-central-repository","text":"Jobs are configured and scheduled through the front-end software. A single cron job is required to handle the launching of jobs based on schedule in the central repository. All information gathered about the job success, partitions offloaded, etc is stored in the central repository.","title":"Full Conductor for Gluent with Central Repository"},{"location":"3.0.x/install-3.0.x/#prerequisites_1","text":"Gluent Data Platform 4.1.0+ Installed Central Repository Database Installed (see C4G Frontend Setup Guide)","title":"Prerequisites"},{"location":"3.0.x/install-3.0.x/#unpack-software","text":"A tar file will be supplied. The tar file should be unpacked in a directory such as, c4g-scripts or scripts or similar. For example: cd /u01/app/gluent mkdir c4g-scripts cd c4g-scripts tar xf {tar file name}","title":"Unpack Software"},{"location":"3.0.x/install-3.0.x/#environment-file-setup","text":"Note on split configuration : If gluent is setup in a split configuration, then certain scripts will not function, and certain variables are not set in the environment files.","title":"Environment File Setup"},{"location":"3.0.x/install-3.0.x/#conductor_for_gluentenv","text":"A template for the conductor_for_gluent.env file can be found under the env/templates directory - it is recommended that you copy the template file as a starting point. PATH - This export of the path is to make sure the oraenv script is in the path. ORACLE_SID - Set this to the Oracle SID of the database which is being offloaded. ORAENV_ASK - Set for no prompts. oraenv - script to set the oracle environment. Unset ORAENV_ASK As this shell script runs SQL, the SQL_PATH variable is unset, so as not to get possible interference (same name scripts, login.sql files, etc). OFFLOAD_HOME=\"/u01/app/gluent/offload\" - Update OFFLOAD_HOME to the location of the gluent software offload home. . $OFFLOAD_HOME/conf/offload.env - DO NOT CHANGE C4G_REPO NONE - No Repository; standalone mode without a repository RUNTIME- run a local repository that stores information generated a runtime FULL - run a central repository that stores information about jobs, schedules, etc. G_ERROR_WORDS - Words and phrases used when determining if a possible error occurred. TNS_ADMIN - Always set to ${tnsdir} - DO NOT CHANGE AEG_GLUENT_REPO_SERVICE - service name to be used when connecting to the central repository AEG_GLUENT_LOCAL_SERVICE - service name to be used when connecting to the local database dstr - service name used in local repository and standalone mode","title":"conductor_for_gluent.env"},{"location":"3.0.x/install-3.0.x/#run-gluent-jobenv","text":"A template for the file can be found under the env/templates directory - it is recommended that you copy the template file as a starting point. PRECREATED_DBS - true or false (defaults to false) Only add/update if gluent is not allowed to create databases on impala G_BEGIN_NOTIFY - true or false G_BEGIN_MAIL_LIST - email addresses space separated in quotes. G_SUCCESS_NOTIFY - true or false G_SUCCESS_MAIL_LIST - email addresses space separated in quotes. G_ERROR_NOTIFY -true or false G_ERROR_MAIL_LIST - email addresses space separated in quotes.","title":"run-gluent-job.env"},{"location":"3.0.x/install-3.0.x/#setup-walletenv","text":"A template for the file can be found under the env/templates directory - it is recommended that you copy the template file as a starting point. AEG_WALLET_LOCATION=/u01/app/gluent/scripts/tns - update to the location to contain the wallet","title":"setup-wallet.env"},{"location":"3.0.x/install-3.0.x/#configuration-file-setup","text":"If not running in the Central Repository mode, then 2 configuration files can be created to set default offload and present parameters. offload-defaults.cfg present-defaults.cfg","title":"Configuration File Setup"},{"location":"3.0.x/install-3.0.x/#user-setup-in-local-database-for-central-repository-mode","text":"A user is needed in the local database with the following username: CONDUCTOR_FOR_GLUENT create user conductor_for_gluent identified by \"{complex password}\" default tablespace users temporary tablespace temp; The privileges needed are: GRANT CONNECT TO CONDUCTOR_FOR_GLUENT; GRANT GLUENT_OFFLOAD_ROLE TO CONDUCTOR_FOR_GLUENT; GRANT SELECT ANY DICTIONARY TO CONDUCTOR_FOR_GLUENT; GRANT SELECT ANY TABLE TO CONDUCTOR_FOR_GLUENT; -- Needed for Conductor for Gluent to do partition maintenance GRANT DROP ANY TABLE TO CONDUCTOR_FOR_GLUENT; GRANT ALTER ANY TABLE TO CONDUCTOR_FOR_GLUENT; An alternative to the ANY TABLE privilege is to perform the grant(s) on the tables to be offloaded.","title":"User Setup in Local Database for Central Repository Mode"},{"location":"3.0.x/install-3.0.x/#tns-setup","text":"This is needed for all 3 modes of the backend software.","title":"TNS Setup"},{"location":"3.0.x/install-3.0.x/#tnsnamesora","text":"A TNSNAMES.ORA file needs to be created in the tns subdirectory. For the no repository option or the local repository option, one entry for the local DB being offloaded is needed. For the central repository mode, two entries are needed: one for local DB and a second for the central repository. Suggested names are as follows: c4g_local c4g_central Historically, the tns entry was: gluent_conn A sample file is located under the tns/sample directory, showing a simple tns entry.","title":"TNSNAMES.ORA"},{"location":"3.0.x/install-3.0.x/#wallet-setup","text":"For Full Conductor for Gluent, run the following: ./setup-wallet new c4g_local ./setup-wallet add c4g_central For Standalone or Runtime Repository modes, run the following: ./setup-wallet new gluent_conn","title":"Wallet Setup"},{"location":"3.0.x/install-3.0.x/#crontab-setup","text":"Once the backend and frontend software are installed, add a cron entry to run the launch script. The job should be like the following with the appropriate path specified: * * * * * /u01/app/gluent/scripts/bin/launch-gluent-jobs {DB/Container Name} > /u01/app/gluent/scripts/log/launch-gluent-jobs-cron.log 2>&1","title":"Crontab Setup"},{"location":"3.0.x/user-guide-3.0.x/","text":"Introduction Conductor for Gluent is an application to help manage Gluent offloads. The Gluent software works on a per database basis. Conductor has an additional unit above a database called a site. A particular installation of Conductor will have one site with one or more databases to manage. The guided flow in Conductor is: Obtain a Gluent Advisor CSV for Conductor file from Gluent Add Database, after adding a database you will be taken to the Candidate Selection Wizard. Upload a Gluent Advisor CSV and select one or more tables. On finishing, you will be taken to the Job Wizard. Name your job, select one or more tables to offload for the job, and schedule the job. At this point, the job will automatically launch based on the schedule. Note: Once some tables have been added either through the candidate selection page or using the add table wizard, the guided flow will not automatically start when closing the add/edit database page. It is not mandatory to follow the guided flow. For example, if you do not have a Gluent Advisor CSV for Conductor file, you can add tables through the add table wizard on the Candidate Review page. Login Enter the Conductor for Gluent Apex URL into your browser. The URL will be something of the form: http://{hostname}:{port}/apex/f?p=100 Once the Conductor for Gluent login form is available, then enter your username and password. Site A site is made up of one or more database, for which jobs can be scheduled for offloading data. At the site level, databases can be added to Conductor, defaults can be set for parameters, notifications and the application, and there is a site level overview of some metrics. Site Home Page From the site level menu, located on the upper left side of the screen, there are the following choices: Site Home - the site home page Application Defaults - where you can change settings that affect the way the application operates From the site home: You can manage site level options: Default Offload Parameters Default Present Parameters Site Level Notification Options Review metrics at the site level: Count of Jobs by week (Last 28 days) for all databases Offload Percentage - percentage of data: offloaded, dropped, or not offloaded from all databases Offloadable Gigabytes of Unselected Advisor Candidates - if an advisor report was uploaded, this is a summary of space from tables which have not been selected Add a New Database - Click on the Add New card from the list. Select a Database to Manage - Click on one of the database cards, to manage its jobs and tables. Edit the details of a database - Click on the Edit Link of a database to go to the maintain database details page, where you change its description, icon color, database link information, etc. Buttons: Default Offload Parameters - Click on the button to go to the Manage Default Offload Parameters for Site page. Default Present Parameters - Depress the button to go to the Manage Default Present Parameters for Site page. Site Level Notification Options - Click on the button to take you to the Manage Notifications for Site page. Links: Database Name - click on the database name to bring up the database home page where you can manage tables and jobs for the database. Edit - click on this link to bring up the maintain database details page and edit details about the database. Databases Database Home Page After clicking on a database on the site home page, you will go to the database home page for that particular database. From the database level menu, located on the upper left side of the screen, there are the following choices: Site Home - the site home page Database Home - the database home page Dashboard - Monitor the status of jobs for the database. Job Maintenance - Add or edit jobs. Table Review - Add or edit details about tables to be offloaded. Candidate Selection - Wizard for selecting candidates from a Gluent Advisor CSV for Conductor. At the top of the page are buttons/links to set offload, present and notification parameters at the database level Followed by some summary information about the database: Advisor Candidates # of tables in the advisor report that have not been selected for offload. Clicking here will take you to the candidate selection wizard. Select Tables # of tables that have been selected as candidates for offload. Clicking here will take you to the table review page. Total Jobs # of jobs that have been created. Clicking here will take you to the job maintenance page. Running Jobs # of jobs currently running. Clicking here will take you to the dashboard. Successful Jobs # of jobs that completed successfully. Clicking here will take you to the dashboard. Jobs in Error State # of jobs where an error has occurred. Clicking here will take you to the dashboard. Review metrics at the database level: Count of Jobs by week (Last 28 days) for this database Offload Percentage - percentage of data: offloaded, dropped, or not offloaded from this database Offloadable Gigabytes of Unselected Advisor Candidates - if an advisor report was uploaded, this is a summary of space from tables which have not been selected Buttons: Default Offload Parameters - Click on the button to go to the Manage Default Offload Parameters for Database page. Default Present Parameters - Depress the button to go to the Manage Default Present Parameters for Database page. Notification - Click on the button to take you to the Manage Notifications for Database page. Calendar (icon) - Located in the Count of Jobs metric (right-hand side above bars), clicking the button will show a calendar for jobs that have run. Maintain Database Details Add Database When adding a new database, enter database name, description, and connection method on this page. Then press Add button. Fields: Name : Any alpha-numeric identifier used to identify the database. [Required field] Description : Any alpha-numeric characters to describe the database. [Required field] Connection Method : No Connection Allowed -or- DB Link. If DB Link is not specified all details about the tables to be offloaded will need to be manually entered. [Required field] Buttons: Add : Add the database details to the Conductor for Gluent repository. Close : Close the page and go back to the site home. Edit Database Any of the fields can be modified. You can switch the color of the database by clicking on the \"Database Icon Color\" link. Once a color is selected from the pick color screen, be sure to press the \"Save\" button. To update the database link information (if that is being used), press on the DB Link Wizard button. Fields: Name : Any alpha-numeric identifier used to identify the database. [Required field] Description : Any alpha-numeric characters to describe the database. [Required field] Connection Method : No Connection Allowed -or- DB Link. If DB Link is not specified all details about the tables to be offloaded will need to be manually entered. [Required field] Buttons: Save : Save the database details to the Conductor for Gluent repository. Delete : Delete the database details to the Conductor for Gluent repository. Close : Close the page. If the database has tables, then you will be directed to the Site home. If the database does not have tables, then you will be directed to the candidate selection wizard. DB Link Wizard : Open the DB Link Wizard to add/edit the database link. Links: Database Icon Color : Bring up the page to pick a color for the database icon. Once a color is selected from the pick color screen, be sure to press the \"Save\" button. DB Link Wizard DB Link Wizard \u2013 Step 1 Enter the host name, port, service name, and password. Press Next to create the database link. Fields: Host Name : Fully qualified host name (FQDN) or IP address. [Required field] TNS Port : Port for the listener on the host that provides access to the database. [Required field] Service Name : The TNS service name for the database. [Required field] Password : The password of the CONDUCTOR_FOR_GLUENT user for this database. [Required field] Buttons: Cancel : Cancel the wizard. Next : When the next button is depressed, a database link will be (re-)created from the details provided, then you move to the 2nd step of the DB Link Wizard. DB Link Wizard \u2013 Step 2 Press Test DB Link to verify that the database link is correct. Press Finish if the test is successful. Press the left arrow to go back and correct any of the database link information. Buttons: Test DB Link : A query will be run with the database link to verify that it completes successfully. Left Arrow : Return to Step 1 of the wizard. Cancel : Cancel the wizard. Finish : When the finish button is hit, the wizard will close. Test DB Link When testing the database link, a message will appear in the DB Link Test Results section for success or failure. Tables There are two ways to add tables to the Conductor for Gluent repository: Candidate Selection Wizard - Tables are selected from a Gluent Advisor report. The candidate selection menu option will bring up the candidate selection wizard. Add Table Wizard - tables are selected from a list of schemas and their tables across a database link based on the privileges provided to the Conductor for Gluent user. The add table wizard button can be found on the table review page. Candidate Selection Wizard Candidate Selection Wizard - Step 1 Step 1 \u2013 Select an Advisor Output File : Select a file or if this is your second time through, you can use the existing file. Multiple files can be uploaded if a new advisor report CSV is obtained. Press Next to continue. Fields: When Upload Advisor Output File (CSV) radio option is selected: Advisor Output File - Click into the field to bring up the file browser and select a file. Date the Advisor was run - It is important to select the correct date, as calculations for the default offload retention is calculated based on this date and information contained in the Gluent Advisor file. Description - Any alphanumeric description for the file. When Use Current Advisor Output radio option is selected: Current file name - The name of the current file (read only). Buttons: Cancel : Cancel the current wizard run. Next : Upload the advisor file into the Conductor for Gluent repository. Candidate Selection Wizard - Step 2 Step 2 \u2013 Select Tables : Select one or more tables that you want to offload by clicking on the table's checkbox. Press Next to continue. Fields: Search : Enter any search string and press enter or hit Go. Once you have searched, you can clear the criteria by hitting the x next to the search term. Buttons: Left Arrow : Return to Step 1 of the wizard. Cancel : Cancel the wizard. Next : Add the selected tables to the Conductor for Gluent repository. Magnifying Glass (icon) : Allows the narrowing of the search to specific field. Go : Search for term entered in the search field. Candidate Selection Wizard - Step 3 Step 3 \u2013 Table Thresholds : The default offload threshold will be determined from the Advisor report. The drop threshold default will be calculated using the application parameter OFFLOAD_DROP_RATIO * offload threshold. Either threshold may be updated if desired. Press Next to continue. Fields: Offload Threshold : For each date range partitioned table, you can enter a threshold for offloading anything older than the number of days specified. It is defaulted based on the Gluent Advisor Report. Drop Threshold : For each date range partitioned table, you can enter a threshold for truncating and dropping anything older than the number of days specified. Buttons: Left Arrow : Return to Step 2 of the wizard. Cancel : Cancel the wizard. Next : Save the values for the table offload and drop thresholds. Candidate Selection Wizard - Step 4 Step 4 \u2013 Partition Details : If a database link is in use, then the partition details will be automatically loaded from the database into the repository. If no connection is available, the partition details will need to be entered manually. Additionally, a column mask can be selected for numbers that represent dates. Press Finish to complete the wizard. Fields: Partition Granularity : The partition granularity corresponds to the Gluent Data Platform parameter --partition-granularity. See Gluent Data Platform documentation for details. Column Mask : The column mask field is a dropdown box that allows selection of a mask on top of number fields when they can be interpreted as a date. Buttons: Left Arrow : Return to Step 3 of the wizard. Cancel : Cancel the wizard. Finish : Complete the wizard. Be sure to hit the save button if you have modified partition details. Row Actions (icon) : Located in the Partition Details section, it allows rows to be added, deleted, duplicated, etc. Save : Save any updates to the partition details. The button is in the Partition Details section. Table Review Page The table review page allows you to add a new table and view information about the tables that have been selected to offload. The following details about tables are available: For all tables, you can: View chart of Frontend-Backend Space View chart of Frontend-Backend Rows View table level offload parameters Additionally, for partitioned tables, you can: View and update the offload and drop threshold, as well as, the offload drop action. View the partition details Fields: Candidate Table : Select a table from the list by clicking on it. Buttons: Close : Close the page and return to the database home page. Add Table Wizard : Complete the wizard. Be sure to hit the save button if you have modified partition details. Table Level Offload Parameters Section Fields: Parameters : A report of all parameters that have been specified for the table. Buttons: Maintain Parameters : Pressing the button will bring up the command parameters page allowing parameters to be added at the table level. See the Command Parameters section for details on adding parameters. Offload and Drop Thresholds Section Fields: Table Partition Type : The frontend partitioning type. (read only) Offload Threshold : Number of days for which a date range (or date masked) should be offloaded. The current date minus the number of days here, will be compared with the partition boundaries. Drop Threshold : Number of days for which a date range (or date masked) should be truncated and dropped. The current date minus the number of days here, will be compared with the partition boundaries. Drop Action after Offload : Use Site Default : Use the value specified at the site level in the Application Parameters page. GENERATE : Generate a script to drop the offloaded partitions after an offload is completed based on Drop Threshold. AUTO : Drop the offloaded partitions after a table is offload based on Drop Threshold. MANUAL : Do Nothing after offload is completed. Drop Verify Level : Use Site Default : Use the value specified at the site level in the Application Parameters page. COUNT : Before dropping a partition perform a count verification of the frontend partition boundaries against both the backend and frontend. The counts must match before proceeding with a partition drop. TRUST : Trust that no modifications (DML) have been performed on the frontend or backend tables before proceeding with a partition drop. No count will be done. Buttons: Save : Save any updates to the thresholds, drop action after upload, or drop verify level fields. The button is in the Offload and Drop Thresholds section. Partition Key Column Details Section Fields: Order : The column order for the partition key columns. (read only) Name : The column name for the partition key columns. (read only) Granularity : The partition granularity corresponds to the Gluent Data Platform parameter --partition-granularity. See Gluent Data Platform documentation for details. (read only) Mask : The column mask field is a date format on top of number fields when they can be interpreted as a date. (read only) Edit Partition Details Dialog Fields: Order : The column order for the partition key columns. Name : The column name for the partition key columns. Granularity : The partition granularity corresponds to the Gluent Data Platform parameter --partition-granularity. See Gluent Data Platform documentation for details. Column Mask : The column mask field is a dropdown box that allows selection of a mask on top of number fields when they can be interpreted as a date. Buttons: Close : Close the page and go back to the table review page. Add Row : Add row to the partition key columns. Save : Save the changes made to the partition details. Row Actions (icon) : It allows rows to be added, deleted, duplicated, etc. Add Table Wizard To add a new table, click the Add Table Wizard button located on the table review page. When a database link is allowed, the first page of the Add Table Wizard will have select lists for the schemas and table names. When next is hit, the partitioning information will be automatically gathered. When no connection is allowed, you will need to manually enter the correct schema, table_name and partitioning type. The second page of the Add Table Wizard will be used to specify the Offload and Drop Thresholds for partition tables. No information is entered for non-partitioned tables. The third page of the Add Table Wizard is used to specify the partition keys when no connection is allowed. Plus, date masking can be specified for cases where a string or number is used to represent a date. No information is entered for non-partitioned tables. Jobs The main page for job maintenance contains cards, each with a job on it. Jobs can be selected by clicking on the card. Clicking on the current card allows the editing of details about the job. The job steps are editable in this page. The Job Add Wizard and calendar view are available by pressing the corresponding buttons. Job Page with No Jobs Before adding any jobs, the screen will show No records found. To start adding jobs, hit the Add Job Wizard button Add Job Wizard - Step 1 Step 1: Job Name and Type The job name can be any alpha-numeric characters. The job description is a free form field. The job type is going to be Normal most of the time. Press Next to continue. Fields: Job Name : An alpha-numeric name for the job with no spaces or special characters. It must be unique across all databases. Job Description : An alpha-numeric description of the job. Job Type : Normal is going to be the job type for 99% of the jobs. A rare case calls for a Duplicate Table job type, when there are duplicate copies of tables that need to be offloaded in multiple schemas. The duplicate job type will be covered in a separate section in Appendix A. Buttons: Cancel : Cancel the wizard. Next : The Job will be saved when the next button is depressed, and you will go to Step 2. Add Job Wizard - Step 2 Step 2: Job Steps Select the step type. Then select the table for the step. Select if the step is enabled or disabled. All steps also have a step comment. Other fields will depend on the step type. Press Next to continue. Radio Selector: Next Action: Save below job step and proceed to scheduling - Save the job step and move to Step 3 of the wizard. Save below job step and add another job step - Save the job step and stay on Step 2 of the wizard. Save below job step and add parameters for it - Save the job step and go to the command parameters page to add parameters to the job step. After the command parameters page, you will be returned to Step 2 of the wizard. Do not save below job step and proceed to scheduling - Do not add the job step and move to Step 3 of the wizard. Fields: Step Type : offload - offload oracle tables to backend. present - present backend table to oracle sched_drop_fe_ds - drop offloaded partitions based on specified threshold sched_gen_drop_fe_ds - generate the statements to drop offloaded partitions based on specified threshold Job Step Class : ongoing - An offload which would run periodically to offload additional datasets. This job step class should be used for partition tables. reset - An offload which would reset the table in the backend and re-offload the current values in the frontend. This job step class should be used for non-partitioned tables where a full refresh is done to the backend. *** Caution: All backend data will be dropped. DATA LOSS WILL OCCUR if all data is not available in frontend table. Table : Table for this job step. Enabled : Yes or No. Job Step Comment : Any alphanumeric comment about this particular job step. Buttons: Left Arrow : Return to Step 1 of the wizard. Cancel : Cancel the wizard. Next : The actions taken when the next button is hit will depend on the Next Action radio selector. Add Job Wizard - Step 3 Step 3: Job Schedule Jobs can be scheduled on a Monthly, Weekly, Daily, or Hourly basis. Only jobs with complete information can be enabled. Fields: Frequency : Monthly - Choose the day of the month (1-28), the hour, and the minute the job should run every month. Weekly - Choose the day of the week, the hour, and the minute the job should run every week. Daily - Choose the hour and minute the job should run every day. Hourly - Choose the minute that the job should run every hour. Enabled : Yes or No. Buttons: Left Arrow : Return to Step 2 of the wizard. Cancel : Cancel the wizard. Next : The actions taken when the next button is hit will depend on the Next Action radio selector. Job Page after Adding a Job Once a job is added, a card can be seen on the page. On each card, the following details are shown: Job Name is the title of the card. Job Mode is the subtitle of the card (execute or verify). Schedule is the text of the card. Job Comment is the sub-text of the card. Enabled/Disabled Enabled jobs will have a Blue circular play icon. Disabled jobs will have a gray circular pause icon. Job Page with a Job Selected Clicking on the card, will show the details of the job. The currently selected card will have a green border around it. The jobs steps will appear below the job cards section, along with parameters for the currently selected job step. Additionally, the notifications for the job will be shown last in a collapsible section (click the arrow to collapse or expand the section). Edit Job Details Clicking on the currently selected card, will bring up the dialog to edit the job details. Fields: Job Name : Name of the job can be any alpha numeric characters. No spaces or special characters. Job Description : Any alpha numeric characters describing the job. Frequency : Monthly - Choose the day of the month (1-28), the hour, and the minute the job should run every month. Weekly - Choose the day of the week, the hour, and the minute the job should run every week. Daily - Choose the hour and minute the job should run every day. Hourly - Choose the minute that the job should run every hour. Enabled : Yes or No. Job Mode : Execute - to execute the job fully. Verify - to run the job to verify the parameters but not actually offload any data. Job Type : Normal is going to be the job type for 99% of the jobs. A rare case calls for a Duplicate Table job type, when there are duplicate copies of tables that need to be offloaded in multiple schemas. The duplicate job type will be covered in a separate section in Appendix A. Buttons: Cancel : Cancel the dialog. Delete : Delete the job if there are no job steps. Save : Save the changes to the job. Job Steps Section In the Job Steps section, you can directly edit the job step fields. The parameters for the job step can be added, updated, or deleted by clicking on the step's maintain link. Fields: Step# : A numeric value to order the steps for execution. Table Id : The table for this step. Job Step Class : ongoing - An offload which would run periodically to offload additional datasets. This job step class should be used for partition tables. reset - An offload which would reset the table in the backend and re-offload the current values in the frontend. This job step class should be used for non-partitioned tables where a full refresh is done to the backend. *** Caution: All backend data will be dropped. DATA LOSS WILL OCCUR if all data is not available in frontend table. Step Type : offload - offload oracle tables to backend. present - present backend table to oracle sched_drop_fe_ds - drop offloaded partitions based on specified threshold sched_gen_drop_fe_ds - generate the statements to drop offloaded partitions based on specified threshold Enabled : Yes or No. Job Step Comment : Any alphanumeric comment about this particular job step. Backend Table : Only used for present commands. Offload Specification : The value can be used for some specialized offload methods: Retention based on # partitions: Specify a \"P\" with a number, and Conductor will offload partitions beyond the number specified. e.g., if 6 is specified and there are 12 partitions, Conductor will specify a \"--less-than-value\" parameter that results in partitions 7-12 being offloaded (if they have not been offloaded already). Specific --less-than-value: Specify a \"L\" with a value, and Conductor will supply the value in the --less-than-value parameter when offloading. Parameters : Link to maintain parameters for the job step. Links: Maintain : Pressing the button will bring up the command parameters page allowing parameters to be added at the job step level. See the Command Parameters section for details on adding parameters. Buttons: Cancel : Cancel the dialog. Delete : Delete the job if there are no job steps. Save : Save the changes to the job. Future Job Calendar Displays jobs that will run based on their projected schedule in a calendar view. Buttons: Close : Close the dialog. Left Arrow (icon) : Move backward by month. Right Arrow (icon) : Move forward by month. Today : Go to Today on the calendar. Month : Month view. Week : Week view. Day : Day view. List : View as a list. Dashboard The dashboard allows for monitoring of jobs. Job States : The donut graph shows a summary by state of the jobs. The state pieces can be clicked on to drill down into the run job details. Recent Jobs : The 10 most recent jobs. Drilldown to the run job details by clicking on the job id. Also, the job name can be selected to drill down to the job details. Fields: Auto-Refresh Interval : Dropdown allowing a selection to set an auto-refresh interval. Buttons: Close : Close the page. Takes you back to the Database Home. Refresh : Refresh the page manually. Calendar (icon) : Opens the job calendar dialog. Links: Piece of Job State Donut : Pressing one of the state pieces will bring up the run job details page for all jobs with the state. Job Id : Pressing the link will bring up the run job details page for the job with that job id and with that job state. Job Name : Pressing the link will take you to the job maintenance page. Job Calendar Displays jobs that have run in a calendar view. Hovering on a job will show the start and end time for the job. Clicking on the job will bring up the run job details page for the job id. Buttons: Close : Close the dialog. Left Arrow (icon) : Move backward by month. Right Arrow (icon) : Move forward by month. Today : Go to Today on the calendar. Month : Month view. Week : Week view. Day : Day view. List : View as a list. Run Job Details The run job details page shows the details of a run job. Sections Sections: Run Jobs : Run job level details. Run Job Steps : Details on each run job step. Command Details : Commands are those job steps executing an actual Gluent Data Platform command. Run Jobs Section Fields: Id - internal job id (read only) Job Name (read only) Job Mode (read only) Run Job State - dropdown to allow a job in error state to be aborted, resumed, or restarted. [Only if run job in ERROR state] Start Timestamp (read only) Finish Timestamp (read only) Description (read only) Buttons: Refresh (icon) : Refresh the section. Save : Save change to Run Job State field. [Only if run job in ERROR state] Run Job Steps Section Fields: # - internal step number (read only) State - internal run job state (read only) Step Type (read only) Step Table Job Step Offload Spec - internal offload specification details (read only) Buttons: Refresh (icon) : Refresh the section. Command Details Section Fields: Id - internal command id (read only) Start Timestamp (read only) Finish Timestamp (read only) Status (read only) Status Details (read only) Log File Name - Gluent Data Platform log file name (read only) Buttons: Refresh (icon) : Refresh the section. Handling a Job in Error State A job can be updated from error state on the run job details page. The run job details page can be accessed by: Clicking on the job_id link for a job in error state from the Recent Jobs list. Selecting one or more jobs in error state by selecting the Error donut piece. Once the job is up in the run job details page, double-click on the Run Job State field. This will allow access to the dropdown list to handle the job. The options shown will be: Here is what each option will do: Abort the Job Run - Change the state of the job to aborted. The run job cannot be resumed or started once this is done. The job will run from the beginning on the next scheduled run. ERROR in Job Run - Leave the job in error state. A job in error state will not run on its next scheduled date/time. Resume the Job - Job will run at the start of the next minute. The job will resume where it left off with the same job settings as when the job started. This option would be used when job was affected by outside forces. For example, a network outage caused the job to fail because it could not connect to the backend. Rewrite the Job File and Resume the Job - Job will run at the start of the next minute. Before resuming where it left off, the job will rewrite the job file to pick up any changes to job parameters or other job step information that has been updated. This option would be used in cases where an additional parameter is needed or something else about the job was specified incorrectly. Command Parameters Command parameters are Gluent Data Platform parameters that can be specified to be used by offload or present commands executed by Conductor for Gluent. They can be specified at different levels of operation: Site Level - Parameters will be used for every offload or present command executed across all the databases. Database Level - Parameters will be used for every offload or present command executed for that specific database. Table Level - Parameters will be used for every offload or present command executed for that specific table. Job Step Level - Parameters will be used for every offload or present command executed for that specific job step. In the above example screen, the command parameters are being maintained for offload commands at the site level. Add Command Parameter Here is the flow of adding a parameter. Before adding a parameter to a job step Hit the Add Parameter button. Add Parameter: Initial Screen Click on the dropdown Add Parameter: Dropdown list Select a parameter from the dropdown list. Add Parameter: Specify value If the parameter requires a value, that is entered and then hit Add button. After adding a parameter to a job step Once the parameter is added, it will show up in the report for that job step. Job Notifications The implementation of notifications is different than that of parameters. It is not an accumulation but an override system: Job Level - Job notifications override any notifications at the database or site level. Database Level - Database level notification will be used when there are no notifications set at the job level. Site Level - Values entered at the site level will be used when there are no notifications at the database level and at the job level. Notifications are sent at the following points of a job: When Job Begins When Job Succeeds If Job has an Error Notifications can be enabled and disabled. Fields: Email Addresses for Notifications when Job Begins Enabled toggle for Notifications when Job Begins Email Addresses for Notifications when Job Succeeds Enabled toggle for Notifications when Job Succeeds Email Addresses for Notifications if Job has an Error Enabled toggle for Notifications if Job has an Error Buttons: Close - Close the dialog. Delete - Delete the notifications. Save - Save any changes made to the notifications. Application Defaults The application defaults are parameters that affect the way the Conductor for Gluent functions. Here is a list of the parameters and how they work: CREATE_BACKEND_DB \u2013 Controls whether the parameter \u2013create-backend-db will be included on offload commands. If the backend system allows the gluent user to create databases, then it should be set to YES. If the backend system does not allow the gluent user to create databases, then set to NO. DROP_VERIFY_EXPIRY \u2013 (for future use) DROP_VERIFY_LEVEL \u2013 Controls the default value for the DROP_VERIFY_LEVEL on tables. COUNT : Before dropping a partition perform a count verification of the frontend partition boundaries against both the backend and frontend. The counts must match before proceeding with a partition drop. TRUST : Trust that no modifications (DML) have been performed on the frontend or backend tables before proceeding with a partition drop. No count will be done. The DROP_VERIFY_LEVEL can be over-ridden at the table level. - JOB_LAUNCH_INTERVAL \u2013 Controls the granularity of the drop down for minutes in the job scheduler. If set to 1, you can specify any minute of the hour (0-59). If you specify 15, you can specify 0, 15, 30, 45. - OFFLOAD_DROP_RATIO \u2013 Controls the default value for the DROP_THRESHOLD on tables. The value in this field will be multiplied with the OFFLOAD_THRESHOLD to determine the default for the DROP_THRESHOLD. - OFFLOAD_DROP_ACTION \u2013 This is the site-wide default for whether an offload job step should attempt to GENERATE : Generate a script to drop the offloaded partitions after an offload is completed based on Drop Threshold. AUTO : Drop the offloaded partitions after a table is offload based on Drop Threshold. MANUAL : Do Nothing after offload is completed. The OFFLOAD_DROP_ACTION can be over-ridden at the table level. Double-click in the Value field to edit the parameter value. Appendix A Duplicate Table Job When there are duplicate copies of tables that need to be offloaded in multiple schemas. An example of this would be if a company had a schema per client with the same tables under each schema. A Duplicate Table Job is added through the Add Job Wizard , however, only step 1 is entered. After completing step 1, you will be taken back to the main job maintenance page. Once you select the job, you can start adding elements to the configuration. The different types of elements in a configuration are: Duplicate Enter duplicate table details. Only a table name is specified (no schema/owner), as there are multiple duplicate tables across the database The duplicate element will look for the specified table name across all schemas in the database. Include Enter the details for a specific table that should be included in the job. Enter a full table name with owner/schema and table names specified. Exclude Enter the details for a specific table that should be excluded in the job. Enter a full table name with owner/schema and table names specified. Example A call center company has one schema for each client that they service through their call center. Under each of those client schemas, they have a CALL_DETAILS table which needs to be offload. In addition, they have a training schema, which has a CALL_DETAILS table that should not be offloaded. The configuration elements for this scenario are: Duplicate, CALL_DETAILS Exclude, TRAINING.CALL_DETAILS This will result in a job being generated based on the frequency desired that will have all the CALL_DETAILS tables except the one from the TRAINING schema.","title":"User Guide"},{"location":"3.0.x/user-guide-3.0.x/#introduction","text":"Conductor for Gluent is an application to help manage Gluent offloads. The Gluent software works on a per database basis. Conductor has an additional unit above a database called a site. A particular installation of Conductor will have one site with one or more databases to manage. The guided flow in Conductor is: Obtain a Gluent Advisor CSV for Conductor file from Gluent Add Database, after adding a database you will be taken to the Candidate Selection Wizard. Upload a Gluent Advisor CSV and select one or more tables. On finishing, you will be taken to the Job Wizard. Name your job, select one or more tables to offload for the job, and schedule the job. At this point, the job will automatically launch based on the schedule. Note: Once some tables have been added either through the candidate selection page or using the add table wizard, the guided flow will not automatically start when closing the add/edit database page. It is not mandatory to follow the guided flow. For example, if you do not have a Gluent Advisor CSV for Conductor file, you can add tables through the add table wizard on the Candidate Review page.","title":"Introduction"},{"location":"3.0.x/user-guide-3.0.x/#login","text":"Enter the Conductor for Gluent Apex URL into your browser. The URL will be something of the form: http://{hostname}:{port}/apex/f?p=100 Once the Conductor for Gluent login form is available, then enter your username and password.","title":"Login"},{"location":"3.0.x/user-guide-3.0.x/#site","text":"A site is made up of one or more database, for which jobs can be scheduled for offloading data. At the site level, databases can be added to Conductor, defaults can be set for parameters, notifications and the application, and there is a site level overview of some metrics.","title":"Site"},{"location":"3.0.x/user-guide-3.0.x/#site-home-page","text":"From the site level menu, located on the upper left side of the screen, there are the following choices: Site Home - the site home page Application Defaults - where you can change settings that affect the way the application operates From the site home: You can manage site level options: Default Offload Parameters Default Present Parameters Site Level Notification Options Review metrics at the site level: Count of Jobs by week (Last 28 days) for all databases Offload Percentage - percentage of data: offloaded, dropped, or not offloaded from all databases Offloadable Gigabytes of Unselected Advisor Candidates - if an advisor report was uploaded, this is a summary of space from tables which have not been selected Add a New Database - Click on the Add New card from the list. Select a Database to Manage - Click on one of the database cards, to manage its jobs and tables. Edit the details of a database - Click on the Edit Link of a database to go to the maintain database details page, where you change its description, icon color, database link information, etc. Buttons: Default Offload Parameters - Click on the button to go to the Manage Default Offload Parameters for Site page. Default Present Parameters - Depress the button to go to the Manage Default Present Parameters for Site page. Site Level Notification Options - Click on the button to take you to the Manage Notifications for Site page. Links: Database Name - click on the database name to bring up the database home page where you can manage tables and jobs for the database. Edit - click on this link to bring up the maintain database details page and edit details about the database.","title":"Site Home Page"},{"location":"3.0.x/user-guide-3.0.x/#databases","text":"","title":"Databases"},{"location":"3.0.x/user-guide-3.0.x/#database-home-page","text":"After clicking on a database on the site home page, you will go to the database home page for that particular database. From the database level menu, located on the upper left side of the screen, there are the following choices: Site Home - the site home page Database Home - the database home page Dashboard - Monitor the status of jobs for the database. Job Maintenance - Add or edit jobs. Table Review - Add or edit details about tables to be offloaded. Candidate Selection - Wizard for selecting candidates from a Gluent Advisor CSV for Conductor. At the top of the page are buttons/links to set offload, present and notification parameters at the database level Followed by some summary information about the database: Advisor Candidates # of tables in the advisor report that have not been selected for offload. Clicking here will take you to the candidate selection wizard. Select Tables # of tables that have been selected as candidates for offload. Clicking here will take you to the table review page. Total Jobs # of jobs that have been created. Clicking here will take you to the job maintenance page. Running Jobs # of jobs currently running. Clicking here will take you to the dashboard. Successful Jobs # of jobs that completed successfully. Clicking here will take you to the dashboard. Jobs in Error State # of jobs where an error has occurred. Clicking here will take you to the dashboard. Review metrics at the database level: Count of Jobs by week (Last 28 days) for this database Offload Percentage - percentage of data: offloaded, dropped, or not offloaded from this database Offloadable Gigabytes of Unselected Advisor Candidates - if an advisor report was uploaded, this is a summary of space from tables which have not been selected Buttons: Default Offload Parameters - Click on the button to go to the Manage Default Offload Parameters for Database page. Default Present Parameters - Depress the button to go to the Manage Default Present Parameters for Database page. Notification - Click on the button to take you to the Manage Notifications for Database page. Calendar (icon) - Located in the Count of Jobs metric (right-hand side above bars), clicking the button will show a calendar for jobs that have run.","title":"Database Home Page"},{"location":"3.0.x/user-guide-3.0.x/#maintain-database-details","text":"","title":"Maintain Database Details"},{"location":"3.0.x/user-guide-3.0.x/#add-database","text":"When adding a new database, enter database name, description, and connection method on this page. Then press Add button. Fields: Name : Any alpha-numeric identifier used to identify the database. [Required field] Description : Any alpha-numeric characters to describe the database. [Required field] Connection Method : No Connection Allowed -or- DB Link. If DB Link is not specified all details about the tables to be offloaded will need to be manually entered. [Required field] Buttons: Add : Add the database details to the Conductor for Gluent repository. Close : Close the page and go back to the site home.","title":"Add Database"},{"location":"3.0.x/user-guide-3.0.x/#edit-database","text":"Any of the fields can be modified. You can switch the color of the database by clicking on the \"Database Icon Color\" link. Once a color is selected from the pick color screen, be sure to press the \"Save\" button. To update the database link information (if that is being used), press on the DB Link Wizard button. Fields: Name : Any alpha-numeric identifier used to identify the database. [Required field] Description : Any alpha-numeric characters to describe the database. [Required field] Connection Method : No Connection Allowed -or- DB Link. If DB Link is not specified all details about the tables to be offloaded will need to be manually entered. [Required field] Buttons: Save : Save the database details to the Conductor for Gluent repository. Delete : Delete the database details to the Conductor for Gluent repository. Close : Close the page. If the database has tables, then you will be directed to the Site home. If the database does not have tables, then you will be directed to the candidate selection wizard. DB Link Wizard : Open the DB Link Wizard to add/edit the database link. Links: Database Icon Color : Bring up the page to pick a color for the database icon. Once a color is selected from the pick color screen, be sure to press the \"Save\" button.","title":"Edit Database"},{"location":"3.0.x/user-guide-3.0.x/#db-link-wizard","text":"","title":"DB Link Wizard"},{"location":"3.0.x/user-guide-3.0.x/#db-link-wizard-step-1","text":"Enter the host name, port, service name, and password. Press Next to create the database link. Fields: Host Name : Fully qualified host name (FQDN) or IP address. [Required field] TNS Port : Port for the listener on the host that provides access to the database. [Required field] Service Name : The TNS service name for the database. [Required field] Password : The password of the CONDUCTOR_FOR_GLUENT user for this database. [Required field] Buttons: Cancel : Cancel the wizard. Next : When the next button is depressed, a database link will be (re-)created from the details provided, then you move to the 2nd step of the DB Link Wizard.","title":"DB Link Wizard \u2013 Step 1"},{"location":"3.0.x/user-guide-3.0.x/#db-link-wizard-step-2","text":"Press Test DB Link to verify that the database link is correct. Press Finish if the test is successful. Press the left arrow to go back and correct any of the database link information. Buttons: Test DB Link : A query will be run with the database link to verify that it completes successfully. Left Arrow : Return to Step 1 of the wizard. Cancel : Cancel the wizard. Finish : When the finish button is hit, the wizard will close.","title":"DB Link Wizard \u2013 Step 2"},{"location":"3.0.x/user-guide-3.0.x/#test-db-link","text":"When testing the database link, a message will appear in the DB Link Test Results section for success or failure.","title":"Test DB Link"},{"location":"3.0.x/user-guide-3.0.x/#tables","text":"There are two ways to add tables to the Conductor for Gluent repository: Candidate Selection Wizard - Tables are selected from a Gluent Advisor report. The candidate selection menu option will bring up the candidate selection wizard. Add Table Wizard - tables are selected from a list of schemas and their tables across a database link based on the privileges provided to the Conductor for Gluent user. The add table wizard button can be found on the table review page.","title":"Tables"},{"location":"3.0.x/user-guide-3.0.x/#candidate-selection-wizard","text":"","title":"Candidate Selection Wizard"},{"location":"3.0.x/user-guide-3.0.x/#candidate-selection-wizard-step-1","text":"Step 1 \u2013 Select an Advisor Output File : Select a file or if this is your second time through, you can use the existing file. Multiple files can be uploaded if a new advisor report CSV is obtained. Press Next to continue. Fields: When Upload Advisor Output File (CSV) radio option is selected: Advisor Output File - Click into the field to bring up the file browser and select a file. Date the Advisor was run - It is important to select the correct date, as calculations for the default offload retention is calculated based on this date and information contained in the Gluent Advisor file. Description - Any alphanumeric description for the file. When Use Current Advisor Output radio option is selected: Current file name - The name of the current file (read only). Buttons: Cancel : Cancel the current wizard run. Next : Upload the advisor file into the Conductor for Gluent repository.","title":"Candidate Selection Wizard - Step 1"},{"location":"3.0.x/user-guide-3.0.x/#candidate-selection-wizard-step-2","text":"Step 2 \u2013 Select Tables : Select one or more tables that you want to offload by clicking on the table's checkbox. Press Next to continue. Fields: Search : Enter any search string and press enter or hit Go. Once you have searched, you can clear the criteria by hitting the x next to the search term. Buttons: Left Arrow : Return to Step 1 of the wizard. Cancel : Cancel the wizard. Next : Add the selected tables to the Conductor for Gluent repository. Magnifying Glass (icon) : Allows the narrowing of the search to specific field. Go : Search for term entered in the search field.","title":"Candidate Selection Wizard - Step 2"},{"location":"3.0.x/user-guide-3.0.x/#candidate-selection-wizard-step-3","text":"Step 3 \u2013 Table Thresholds : The default offload threshold will be determined from the Advisor report. The drop threshold default will be calculated using the application parameter OFFLOAD_DROP_RATIO * offload threshold. Either threshold may be updated if desired. Press Next to continue. Fields: Offload Threshold : For each date range partitioned table, you can enter a threshold for offloading anything older than the number of days specified. It is defaulted based on the Gluent Advisor Report. Drop Threshold : For each date range partitioned table, you can enter a threshold for truncating and dropping anything older than the number of days specified. Buttons: Left Arrow : Return to Step 2 of the wizard. Cancel : Cancel the wizard. Next : Save the values for the table offload and drop thresholds.","title":"Candidate Selection Wizard - Step 3"},{"location":"3.0.x/user-guide-3.0.x/#candidate-selection-wizard-step-4","text":"Step 4 \u2013 Partition Details : If a database link is in use, then the partition details will be automatically loaded from the database into the repository. If no connection is available, the partition details will need to be entered manually. Additionally, a column mask can be selected for numbers that represent dates. Press Finish to complete the wizard. Fields: Partition Granularity : The partition granularity corresponds to the Gluent Data Platform parameter --partition-granularity. See Gluent Data Platform documentation for details. Column Mask : The column mask field is a dropdown box that allows selection of a mask on top of number fields when they can be interpreted as a date. Buttons: Left Arrow : Return to Step 3 of the wizard. Cancel : Cancel the wizard. Finish : Complete the wizard. Be sure to hit the save button if you have modified partition details. Row Actions (icon) : Located in the Partition Details section, it allows rows to be added, deleted, duplicated, etc. Save : Save any updates to the partition details. The button is in the Partition Details section.","title":"Candidate Selection Wizard - Step 4"},{"location":"3.0.x/user-guide-3.0.x/#table-review-page","text":"The table review page allows you to add a new table and view information about the tables that have been selected to offload. The following details about tables are available: For all tables, you can: View chart of Frontend-Backend Space View chart of Frontend-Backend Rows View table level offload parameters Additionally, for partitioned tables, you can: View and update the offload and drop threshold, as well as, the offload drop action. View the partition details Fields: Candidate Table : Select a table from the list by clicking on it. Buttons: Close : Close the page and return to the database home page. Add Table Wizard : Complete the wizard. Be sure to hit the save button if you have modified partition details.","title":"Table Review Page"},{"location":"3.0.x/user-guide-3.0.x/#table-level-offload-parameters-section","text":"Fields: Parameters : A report of all parameters that have been specified for the table. Buttons: Maintain Parameters : Pressing the button will bring up the command parameters page allowing parameters to be added at the table level. See the Command Parameters section for details on adding parameters.","title":"Table Level Offload Parameters Section"},{"location":"3.0.x/user-guide-3.0.x/#offload-and-drop-thresholds-section","text":"Fields: Table Partition Type : The frontend partitioning type. (read only) Offload Threshold : Number of days for which a date range (or date masked) should be offloaded. The current date minus the number of days here, will be compared with the partition boundaries. Drop Threshold : Number of days for which a date range (or date masked) should be truncated and dropped. The current date minus the number of days here, will be compared with the partition boundaries. Drop Action after Offload : Use Site Default : Use the value specified at the site level in the Application Parameters page. GENERATE : Generate a script to drop the offloaded partitions after an offload is completed based on Drop Threshold. AUTO : Drop the offloaded partitions after a table is offload based on Drop Threshold. MANUAL : Do Nothing after offload is completed. Drop Verify Level : Use Site Default : Use the value specified at the site level in the Application Parameters page. COUNT : Before dropping a partition perform a count verification of the frontend partition boundaries against both the backend and frontend. The counts must match before proceeding with a partition drop. TRUST : Trust that no modifications (DML) have been performed on the frontend or backend tables before proceeding with a partition drop. No count will be done. Buttons: Save : Save any updates to the thresholds, drop action after upload, or drop verify level fields. The button is in the Offload and Drop Thresholds section.","title":"Offload and Drop Thresholds Section"},{"location":"3.0.x/user-guide-3.0.x/#partition-key-column-details-section","text":"Fields: Order : The column order for the partition key columns. (read only) Name : The column name for the partition key columns. (read only) Granularity : The partition granularity corresponds to the Gluent Data Platform parameter --partition-granularity. See Gluent Data Platform documentation for details. (read only) Mask : The column mask field is a date format on top of number fields when they can be interpreted as a date. (read only)","title":"Partition Key Column Details Section"},{"location":"3.0.x/user-guide-3.0.x/#edit-partition-details-dialog","text":"Fields: Order : The column order for the partition key columns. Name : The column name for the partition key columns. Granularity : The partition granularity corresponds to the Gluent Data Platform parameter --partition-granularity. See Gluent Data Platform documentation for details. Column Mask : The column mask field is a dropdown box that allows selection of a mask on top of number fields when they can be interpreted as a date. Buttons: Close : Close the page and go back to the table review page. Add Row : Add row to the partition key columns. Save : Save the changes made to the partition details. Row Actions (icon) : It allows rows to be added, deleted, duplicated, etc.","title":"Edit Partition Details Dialog"},{"location":"3.0.x/user-guide-3.0.x/#add-table-wizard","text":"To add a new table, click the Add Table Wizard button located on the table review page. When a database link is allowed, the first page of the Add Table Wizard will have select lists for the schemas and table names. When next is hit, the partitioning information will be automatically gathered. When no connection is allowed, you will need to manually enter the correct schema, table_name and partitioning type. The second page of the Add Table Wizard will be used to specify the Offload and Drop Thresholds for partition tables. No information is entered for non-partitioned tables. The third page of the Add Table Wizard is used to specify the partition keys when no connection is allowed. Plus, date masking can be specified for cases where a string or number is used to represent a date. No information is entered for non-partitioned tables.","title":"Add Table Wizard"},{"location":"3.0.x/user-guide-3.0.x/#jobs","text":"The main page for job maintenance contains cards, each with a job on it. Jobs can be selected by clicking on the card. Clicking on the current card allows the editing of details about the job. The job steps are editable in this page. The Job Add Wizard and calendar view are available by pressing the corresponding buttons.","title":"Jobs"},{"location":"3.0.x/user-guide-3.0.x/#job-page-with-no-jobs","text":"Before adding any jobs, the screen will show No records found. To start adding jobs, hit the Add Job Wizard button","title":"Job Page with No Jobs"},{"location":"3.0.x/user-guide-3.0.x/#add-job-wizard-step-1","text":"Step 1: Job Name and Type The job name can be any alpha-numeric characters. The job description is a free form field. The job type is going to be Normal most of the time. Press Next to continue. Fields: Job Name : An alpha-numeric name for the job with no spaces or special characters. It must be unique across all databases. Job Description : An alpha-numeric description of the job. Job Type : Normal is going to be the job type for 99% of the jobs. A rare case calls for a Duplicate Table job type, when there are duplicate copies of tables that need to be offloaded in multiple schemas. The duplicate job type will be covered in a separate section in Appendix A. Buttons: Cancel : Cancel the wizard. Next : The Job will be saved when the next button is depressed, and you will go to Step 2.","title":"Add Job Wizard - Step 1"},{"location":"3.0.x/user-guide-3.0.x/#add-job-wizard-step-2","text":"Step 2: Job Steps Select the step type. Then select the table for the step. Select if the step is enabled or disabled. All steps also have a step comment. Other fields will depend on the step type. Press Next to continue. Radio Selector: Next Action: Save below job step and proceed to scheduling - Save the job step and move to Step 3 of the wizard. Save below job step and add another job step - Save the job step and stay on Step 2 of the wizard. Save below job step and add parameters for it - Save the job step and go to the command parameters page to add parameters to the job step. After the command parameters page, you will be returned to Step 2 of the wizard. Do not save below job step and proceed to scheduling - Do not add the job step and move to Step 3 of the wizard. Fields: Step Type : offload - offload oracle tables to backend. present - present backend table to oracle sched_drop_fe_ds - drop offloaded partitions based on specified threshold sched_gen_drop_fe_ds - generate the statements to drop offloaded partitions based on specified threshold Job Step Class : ongoing - An offload which would run periodically to offload additional datasets. This job step class should be used for partition tables. reset - An offload which would reset the table in the backend and re-offload the current values in the frontend. This job step class should be used for non-partitioned tables where a full refresh is done to the backend. *** Caution: All backend data will be dropped. DATA LOSS WILL OCCUR if all data is not available in frontend table. Table : Table for this job step. Enabled : Yes or No. Job Step Comment : Any alphanumeric comment about this particular job step. Buttons: Left Arrow : Return to Step 1 of the wizard. Cancel : Cancel the wizard. Next : The actions taken when the next button is hit will depend on the Next Action radio selector.","title":"Add Job Wizard - Step 2"},{"location":"3.0.x/user-guide-3.0.x/#add-job-wizard-step-3","text":"Step 3: Job Schedule Jobs can be scheduled on a Monthly, Weekly, Daily, or Hourly basis. Only jobs with complete information can be enabled. Fields: Frequency : Monthly - Choose the day of the month (1-28), the hour, and the minute the job should run every month. Weekly - Choose the day of the week, the hour, and the minute the job should run every week. Daily - Choose the hour and minute the job should run every day. Hourly - Choose the minute that the job should run every hour. Enabled : Yes or No. Buttons: Left Arrow : Return to Step 2 of the wizard. Cancel : Cancel the wizard. Next : The actions taken when the next button is hit will depend on the Next Action radio selector.","title":"Add Job Wizard - Step 3"},{"location":"3.0.x/user-guide-3.0.x/#job-page-after-adding-a-job","text":"Once a job is added, a card can be seen on the page. On each card, the following details are shown: Job Name is the title of the card. Job Mode is the subtitle of the card (execute or verify). Schedule is the text of the card. Job Comment is the sub-text of the card. Enabled/Disabled Enabled jobs will have a Blue circular play icon. Disabled jobs will have a gray circular pause icon.","title":"Job Page after Adding a Job"},{"location":"3.0.x/user-guide-3.0.x/#job-page-with-a-job-selected","text":"Clicking on the card, will show the details of the job. The currently selected card will have a green border around it. The jobs steps will appear below the job cards section, along with parameters for the currently selected job step. Additionally, the notifications for the job will be shown last in a collapsible section (click the arrow to collapse or expand the section).","title":"Job Page with a Job Selected"},{"location":"3.0.x/user-guide-3.0.x/#edit-job-details","text":"Clicking on the currently selected card, will bring up the dialog to edit the job details. Fields: Job Name : Name of the job can be any alpha numeric characters. No spaces or special characters. Job Description : Any alpha numeric characters describing the job. Frequency : Monthly - Choose the day of the month (1-28), the hour, and the minute the job should run every month. Weekly - Choose the day of the week, the hour, and the minute the job should run every week. Daily - Choose the hour and minute the job should run every day. Hourly - Choose the minute that the job should run every hour. Enabled : Yes or No. Job Mode : Execute - to execute the job fully. Verify - to run the job to verify the parameters but not actually offload any data. Job Type : Normal is going to be the job type for 99% of the jobs. A rare case calls for a Duplicate Table job type, when there are duplicate copies of tables that need to be offloaded in multiple schemas. The duplicate job type will be covered in a separate section in Appendix A. Buttons: Cancel : Cancel the dialog. Delete : Delete the job if there are no job steps. Save : Save the changes to the job.","title":"Edit Job Details"},{"location":"3.0.x/user-guide-3.0.x/#job-steps-section","text":"In the Job Steps section, you can directly edit the job step fields. The parameters for the job step can be added, updated, or deleted by clicking on the step's maintain link. Fields: Step# : A numeric value to order the steps for execution. Table Id : The table for this step. Job Step Class : ongoing - An offload which would run periodically to offload additional datasets. This job step class should be used for partition tables. reset - An offload which would reset the table in the backend and re-offload the current values in the frontend. This job step class should be used for non-partitioned tables where a full refresh is done to the backend. *** Caution: All backend data will be dropped. DATA LOSS WILL OCCUR if all data is not available in frontend table. Step Type : offload - offload oracle tables to backend. present - present backend table to oracle sched_drop_fe_ds - drop offloaded partitions based on specified threshold sched_gen_drop_fe_ds - generate the statements to drop offloaded partitions based on specified threshold Enabled : Yes or No. Job Step Comment : Any alphanumeric comment about this particular job step. Backend Table : Only used for present commands. Offload Specification : The value can be used for some specialized offload methods: Retention based on # partitions: Specify a \"P\" with a number, and Conductor will offload partitions beyond the number specified. e.g., if 6 is specified and there are 12 partitions, Conductor will specify a \"--less-than-value\" parameter that results in partitions 7-12 being offloaded (if they have not been offloaded already). Specific --less-than-value: Specify a \"L\" with a value, and Conductor will supply the value in the --less-than-value parameter when offloading. Parameters : Link to maintain parameters for the job step. Links: Maintain : Pressing the button will bring up the command parameters page allowing parameters to be added at the job step level. See the Command Parameters section for details on adding parameters. Buttons: Cancel : Cancel the dialog. Delete : Delete the job if there are no job steps. Save : Save the changes to the job.","title":"Job Steps Section"},{"location":"3.0.x/user-guide-3.0.x/#future-job-calendar","text":"Displays jobs that will run based on their projected schedule in a calendar view. Buttons: Close : Close the dialog. Left Arrow (icon) : Move backward by month. Right Arrow (icon) : Move forward by month. Today : Go to Today on the calendar. Month : Month view. Week : Week view. Day : Day view. List : View as a list.","title":"Future Job Calendar"},{"location":"3.0.x/user-guide-3.0.x/#dashboard","text":"The dashboard allows for monitoring of jobs. Job States : The donut graph shows a summary by state of the jobs. The state pieces can be clicked on to drill down into the run job details. Recent Jobs : The 10 most recent jobs. Drilldown to the run job details by clicking on the job id. Also, the job name can be selected to drill down to the job details. Fields: Auto-Refresh Interval : Dropdown allowing a selection to set an auto-refresh interval. Buttons: Close : Close the page. Takes you back to the Database Home. Refresh : Refresh the page manually. Calendar (icon) : Opens the job calendar dialog. Links: Piece of Job State Donut : Pressing one of the state pieces will bring up the run job details page for all jobs with the state. Job Id : Pressing the link will bring up the run job details page for the job with that job id and with that job state. Job Name : Pressing the link will take you to the job maintenance page.","title":"Dashboard"},{"location":"3.0.x/user-guide-3.0.x/#job-calendar","text":"Displays jobs that have run in a calendar view. Hovering on a job will show the start and end time for the job. Clicking on the job will bring up the run job details page for the job id. Buttons: Close : Close the dialog. Left Arrow (icon) : Move backward by month. Right Arrow (icon) : Move forward by month. Today : Go to Today on the calendar. Month : Month view. Week : Week view. Day : Day view. List : View as a list.","title":"Job Calendar"},{"location":"3.0.x/user-guide-3.0.x/#run-job-details","text":"The run job details page shows the details of a run job.","title":"Run Job Details"},{"location":"3.0.x/user-guide-3.0.x/#sections","text":"Sections: Run Jobs : Run job level details. Run Job Steps : Details on each run job step. Command Details : Commands are those job steps executing an actual Gluent Data Platform command.","title":"Sections"},{"location":"3.0.x/user-guide-3.0.x/#run-jobs-section","text":"Fields: Id - internal job id (read only) Job Name (read only) Job Mode (read only) Run Job State - dropdown to allow a job in error state to be aborted, resumed, or restarted. [Only if run job in ERROR state] Start Timestamp (read only) Finish Timestamp (read only) Description (read only) Buttons: Refresh (icon) : Refresh the section. Save : Save change to Run Job State field. [Only if run job in ERROR state]","title":"Run Jobs Section"},{"location":"3.0.x/user-guide-3.0.x/#run-job-steps-section","text":"Fields: # - internal step number (read only) State - internal run job state (read only) Step Type (read only) Step Table Job Step Offload Spec - internal offload specification details (read only) Buttons: Refresh (icon) : Refresh the section.","title":"Run Job Steps Section"},{"location":"3.0.x/user-guide-3.0.x/#command-details-section","text":"Fields: Id - internal command id (read only) Start Timestamp (read only) Finish Timestamp (read only) Status (read only) Status Details (read only) Log File Name - Gluent Data Platform log file name (read only) Buttons: Refresh (icon) : Refresh the section.","title":"Command Details Section"},{"location":"3.0.x/user-guide-3.0.x/#handling-a-job-in-error-state","text":"A job can be updated from error state on the run job details page. The run job details page can be accessed by: Clicking on the job_id link for a job in error state from the Recent Jobs list. Selecting one or more jobs in error state by selecting the Error donut piece. Once the job is up in the run job details page, double-click on the Run Job State field. This will allow access to the dropdown list to handle the job. The options shown will be: Here is what each option will do: Abort the Job Run - Change the state of the job to aborted. The run job cannot be resumed or started once this is done. The job will run from the beginning on the next scheduled run. ERROR in Job Run - Leave the job in error state. A job in error state will not run on its next scheduled date/time. Resume the Job - Job will run at the start of the next minute. The job will resume where it left off with the same job settings as when the job started. This option would be used when job was affected by outside forces. For example, a network outage caused the job to fail because it could not connect to the backend. Rewrite the Job File and Resume the Job - Job will run at the start of the next minute. Before resuming where it left off, the job will rewrite the job file to pick up any changes to job parameters or other job step information that has been updated. This option would be used in cases where an additional parameter is needed or something else about the job was specified incorrectly.","title":"Handling a Job in Error State"},{"location":"3.0.x/user-guide-3.0.x/#command-parameters","text":"Command parameters are Gluent Data Platform parameters that can be specified to be used by offload or present commands executed by Conductor for Gluent. They can be specified at different levels of operation: Site Level - Parameters will be used for every offload or present command executed across all the databases. Database Level - Parameters will be used for every offload or present command executed for that specific database. Table Level - Parameters will be used for every offload or present command executed for that specific table. Job Step Level - Parameters will be used for every offload or present command executed for that specific job step. In the above example screen, the command parameters are being maintained for offload commands at the site level.","title":"Command Parameters"},{"location":"3.0.x/user-guide-3.0.x/#add-command-parameter","text":"Here is the flow of adding a parameter.","title":"Add Command Parameter"},{"location":"3.0.x/user-guide-3.0.x/#before-adding-a-parameter-to-a-job-step","text":"Hit the Add Parameter button.","title":"Before adding a parameter to a job step"},{"location":"3.0.x/user-guide-3.0.x/#add-parameter-initial-screen","text":"Click on the dropdown","title":"Add Parameter: Initial Screen"},{"location":"3.0.x/user-guide-3.0.x/#add-parameter-dropdown-list","text":"Select a parameter from the dropdown list.","title":"Add Parameter: Dropdown list"},{"location":"3.0.x/user-guide-3.0.x/#add-parameter-specify-value","text":"If the parameter requires a value, that is entered and then hit Add button.","title":"Add Parameter: Specify value"},{"location":"3.0.x/user-guide-3.0.x/#after-adding-a-parameter-to-a-job-step","text":"Once the parameter is added, it will show up in the report for that job step.","title":"After adding a parameter to a job step"},{"location":"3.0.x/user-guide-3.0.x/#job-notifications","text":"The implementation of notifications is different than that of parameters. It is not an accumulation but an override system: Job Level - Job notifications override any notifications at the database or site level. Database Level - Database level notification will be used when there are no notifications set at the job level. Site Level - Values entered at the site level will be used when there are no notifications at the database level and at the job level. Notifications are sent at the following points of a job: When Job Begins When Job Succeeds If Job has an Error Notifications can be enabled and disabled. Fields: Email Addresses for Notifications when Job Begins Enabled toggle for Notifications when Job Begins Email Addresses for Notifications when Job Succeeds Enabled toggle for Notifications when Job Succeeds Email Addresses for Notifications if Job has an Error Enabled toggle for Notifications if Job has an Error Buttons: Close - Close the dialog. Delete - Delete the notifications. Save - Save any changes made to the notifications.","title":"Job Notifications"},{"location":"3.0.x/user-guide-3.0.x/#application-defaults","text":"The application defaults are parameters that affect the way the Conductor for Gluent functions. Here is a list of the parameters and how they work: CREATE_BACKEND_DB \u2013 Controls whether the parameter \u2013create-backend-db will be included on offload commands. If the backend system allows the gluent user to create databases, then it should be set to YES. If the backend system does not allow the gluent user to create databases, then set to NO. DROP_VERIFY_EXPIRY \u2013 (for future use) DROP_VERIFY_LEVEL \u2013 Controls the default value for the DROP_VERIFY_LEVEL on tables. COUNT : Before dropping a partition perform a count verification of the frontend partition boundaries against both the backend and frontend. The counts must match before proceeding with a partition drop. TRUST : Trust that no modifications (DML) have been performed on the frontend or backend tables before proceeding with a partition drop. No count will be done. The DROP_VERIFY_LEVEL can be over-ridden at the table level. - JOB_LAUNCH_INTERVAL \u2013 Controls the granularity of the drop down for minutes in the job scheduler. If set to 1, you can specify any minute of the hour (0-59). If you specify 15, you can specify 0, 15, 30, 45. - OFFLOAD_DROP_RATIO \u2013 Controls the default value for the DROP_THRESHOLD on tables. The value in this field will be multiplied with the OFFLOAD_THRESHOLD to determine the default for the DROP_THRESHOLD. - OFFLOAD_DROP_ACTION \u2013 This is the site-wide default for whether an offload job step should attempt to GENERATE : Generate a script to drop the offloaded partitions after an offload is completed based on Drop Threshold. AUTO : Drop the offloaded partitions after a table is offload based on Drop Threshold. MANUAL : Do Nothing after offload is completed. The OFFLOAD_DROP_ACTION can be over-ridden at the table level. Double-click in the Value field to edit the parameter value.","title":"Application Defaults"},{"location":"3.0.x/user-guide-3.0.x/#appendix-a","text":"","title":"Appendix A"},{"location":"3.0.x/user-guide-3.0.x/#duplicate-table-job","text":"When there are duplicate copies of tables that need to be offloaded in multiple schemas. An example of this would be if a company had a schema per client with the same tables under each schema. A Duplicate Table Job is added through the Add Job Wizard , however, only step 1 is entered. After completing step 1, you will be taken back to the main job maintenance page. Once you select the job, you can start adding elements to the configuration. The different types of elements in a configuration are: Duplicate Enter duplicate table details. Only a table name is specified (no schema/owner), as there are multiple duplicate tables across the database The duplicate element will look for the specified table name across all schemas in the database. Include Enter the details for a specific table that should be included in the job. Enter a full table name with owner/schema and table names specified. Exclude Enter the details for a specific table that should be excluded in the job. Enter a full table name with owner/schema and table names specified. Example A call center company has one schema for each client that they service through their call center. Under each of those client schemas, they have a CALL_DETAILS table which needs to be offload. In addition, they have a training schema, which has a CALL_DETAILS table that should not be offloaded. The configuration elements for this scenario are: Duplicate, CALL_DETAILS Exclude, TRAINING.CALL_DETAILS This will result in a job being generated based on the frequency desired that will have all the CALL_DETAILS tables except the one from the TRAINING schema.","title":"Duplicate Table Job"}]}